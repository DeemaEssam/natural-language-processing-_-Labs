{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRxgtgvT2SDT"
      },
      "source": [
        "### Evaluate Topic Model in Python: Latent Dirichlet Allocation (LDA)\\\n",
        "##### A step-by-step guide to building interpretable topic models\n",
        "\n",
        "** **\n",
        "*Preface: This article aims to provide consolidated information on the underlying topic and is not to be considered as the original work. The information and the code are repurposed through several online articles, research papers, books, and open-source code*\n",
        "** **\n",
        "\n",
        "In the previous [article](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0), I introduced the concept of topic modeling and walked through the code for developing your first topic model using Latent Dirichlet Allocation (LDA) method in the python using Gensim implementation.\n",
        "\n",
        "Pursuing on that understanding, in this article, we’ll go a few steps deeper by outlining the framework to quantitatively evaluate topic models through the measure of topic coherence and share the code template in python using Gensim implementation to allow for end-to-end model development.\n",
        "\n",
        "### Why evaluate topic models?\n",
        "\n",
        "![img](https://tinyurl.com/y3xznjwq)\n",
        "\n",
        "We know probabilistic topic models, such as LDA, are popular tools for text analysis, providing both a predictive and latent topic representation of the corpus. However, there is a longstanding assumption that the latent space discovered by these models is generally meaningful and useful, and that evaluating such assumptions is challenging due to its unsupervised training process. Besides, there is a no-gold standard list of topics to compare against every corpus.\n",
        "\n",
        "Nevertheless, it is equally important to identify if a trained model is objectively good or bad, as well have an ability to compare different models/methods. To do so, one would require an objective measure for the quality. Traditionally, and still for many practical applications, to evaluate if “the correct thing” has been learned about the corpus, an implicit knowledge and “eyeballing” approaches are used. Ideally, we’d like to capture this information in a single metric that can be maximized, and compared.\n",
        "\n",
        "Let’s take a look at roughly what approaches are commonly used for the evaluation:\n",
        "\n",
        "**Eye Balling Models**\n",
        "- Top N words\n",
        "- Topics / Documents\n",
        "\n",
        "**Intrinsic Evaluation Metrics**\n",
        "- Capturing model semantics\n",
        "- Topics interpretability\n",
        "\n",
        "**Human Judgements**\n",
        "- What is a topic\n",
        "\n",
        "**Extrinsic Evaluation Metrics/Evaluation at task**\n",
        "- Is model good at performing predefined tasks, such as classification\n",
        "\n",
        "Natural language is messy, ambiguous and full of subjective interpretation, and sometimes trying to cleanse ambiguity reduces the language to an unnatural form. In this article, we’ll explore more about topic coherence, an intrinsic evaluation metric, and how you can use it to quantitatively justify the model selection.\n",
        "\n",
        "### What is Topic Coherence?\n",
        "\n",
        "Before we understand topic coherence, let’s briefly look at the perplexity measure. Perplexity as well is one of the intrinsic evaluation metric, and is widely used for language model evaluation. It captures how surprised a model is of new data it has not seen before, and is measured as the normalized log-likelihood of a held-out test set.\n",
        "\n",
        "Focussing on the log-likelihood part, you can think of the perplexity metric as measuring how probable some new unseen data is given the model that was learned earlier. That is to say, how well does the model represent or reproduce the statistics of the held-out data.\n",
        "\n",
        "However, recent studies have shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated.\n",
        "\n",
        "*Optimizing for perplexity may not yield human interpretable topics*\n",
        "\n",
        "This limitation of perplexity measure served as a motivation for more work trying to model the human judgment, and thus *Topic Coherence*.\n",
        "\n",
        "The concept of topic coherence combines a number of measures into a framework to evaluate the coherence between topics inferred by a model. But before that…\n",
        "\n",
        "#### What is topic coherence?\n",
        "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But,\n",
        "\n",
        "#### What is coherence?\n",
        "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But …\n",
        "\n",
        "### Coherence Measures\n",
        "Let’s take quick look at different coherence measures, and how they are calculated:\n",
        "\n",
        "1. `C_v` measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
        "2. `C_p` is based on a sliding window, one-preceding segmentation of the top words and the confirmation measure of Fitelson's coherence\n",
        "3. `C_uci` measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
        "4. `C_umass` is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
        "5. `C_npmi` is an enhanced version of the C_uci coherence using the normalized pointwise mutual information (NPMI)\n",
        "6. `C_a` is based on a context window, a pairwise comparison of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
        "\n",
        "There is, of course, a lot more to the concept of topic model evaluation, and the coherence measure. However, keeping in mind the length, and purpose of this article, let’s apply these concepts into developing a model that is at least better than with the default parameters. Also, we’ll be re-purposing already available online pieces of code to support this exercise instead of re-inventing the wheel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efFtmhNc2SDV"
      },
      "source": [
        "### Model Implementation\n",
        "1. Loading Data\n",
        "2. Data Cleaning\n",
        "3. Phrase Modeling: Bi-grams and Tri-grams\n",
        "4. Data Transformation: Corpus and Dictionary\n",
        "5. Base Model\n",
        "6. Hyper-parameter Tuning\n",
        "7. Final model\n",
        "8. Visualize Results\n",
        "\n",
        "** **\n",
        "\n",
        "For this tutorial, we’ll use the dataset of papers published in NeurIPS (NIPS) conference which is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NeurIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
        "\n",
        "<img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_158/img/nips_logo.png\" alt=\"The logo of NIPS (Neural Information Processing Systems)\">\n",
        "\n",
        "Let’s start by looking at the content of the file\n",
        "\n",
        "** **\n",
        "#### Step 1: Loading Data\n",
        "** **\n",
        "\n",
        "For this tutorial, we’ll use the dataset of papers published in NIPS conference. The NIPS conference (Neural Information Processing Systems) is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
        "\n",
        "Let’s start by looking at the content of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o-K445Sf2SDV",
        "outputId": "aa805d68-bbe3-4ab2-c739-486fb5aec36e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 6560,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1901,\n        \"min\": 1,\n        \"max\": 6603,\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          3087,\n          78,\n          5412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2016,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1992,\n          1990,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"Natural Actor-Critic for Road Traffic Optimisation\",\n          \"Learning Representations by Recirculation\",\n          \"Quantized Kernel Learning for Feature Matching\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Oral\",\n          \"Spotlight\",\n          \"Poster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"3087-natural-actor-critic-for-road-traffic-optimisation.pdf\",\n          \"78-learning-representations-by-recirculation.pdf\",\n          \"5412-quantized-kernel-learning-for-feature-matching.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3244,\n        \"samples\": [\n          \"Tensor CANDECOMP/PARAFAC (CP) decomposition has wide applications in statistical learning of latent variable models and in data mining. In this paper, we propose fast and randomized tensor CP decomposition algorithms based on sketching. We build on the idea of count sketches, but introduce many novel ideas which are unique to tensors. We develop novel methods for randomized com- putation of tensor contractions via FFTs, without explicitly forming the tensors. Such tensor contractions are encountered in decomposition methods such as ten- sor power iterations and alternating least squares. We also design novel colliding hashes for symmetric tensors to further save time in computing the sketches. We then combine these sketching ideas with existing whitening and tensor power iter- ative techniques to obtain the fastest algorithm on both sparse and dense tensors. The quality of approximation under our method does not depend on properties such as sparsity, uniformity of elements, etc. We apply the method for topic mod- eling and obtain competitive results.\",\n          \"Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular, state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such, small displacements of energy from a frequency bin to another as well as variations of timber can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound, the new measure is invariant to shifts of energy to harmonically-related frequencies, as well as to small and local displacements of energy. Equipped with this new measure of fit, the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.\",\n          \"The problem of  multiclass boosting is considered. A new framework,based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6553,\n        \"samples\": [\n          \"550\\n\\nAckley and Littman\\n\\nGeneralization and scaling in reinforcement\\nlearning\\nDavid H. Ackley\\nMichael L. Littman\\nCognitive Science Research Group\\nBellcore\\nMorristown, NJ 07960\\n\\nABSTRACT\\nIn associative reinforcement learning, an environment generates input\\nvectors, a learning system generates possible output vectors, and a reinforcement function computes feedback signals from the input-output\\npairs. The task is to discover and remember input-output pairs that\\ngenerate rewards. Especially difficult cases occur when rewards are\\nrare, since the expected time for any algorithm can grow exponentially\\nwith the size of the problem. Nonetheless, if a reinforcement function\\npossesses regularities, and a learning algorithm exploits them, learning\\ntime can be reduced below that of non-generalizing algorithms. This\\npaper describes a neural network algorithm called complementary reinforcement back-propagation (CRBP), and reports simulation results\\non problems designed to offer differing opportunities for generalization.\\n\\n1\\n\\nREINFORCEMENT LEARNING REQUIRES SEARCH\\n\\nReinforcement learning (Sutton, 1984; Barto & Anandan, 1985; Ackley, 1988; Allen,\\n1989) requires more from a learner than does the more familiar supervised learning\\nparadigm. Supervised learning supplies the correct answers to the learner, whereas\\nreinforcement learning requires the learner to discover the correct outputs before\\nthey can be stored. The reinforcement paradigm divides neatly into search and\\nlearning aspects: When rewarded the system makes internal adjustments to learn\\nthe discovered input-output pair; when punished the system makes internal adjustments to search elsewhere.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n1.1\\n\\nMAKING REINFORCEMENT INTO ERROR\\n\\nFollowing work by Anderson (1986) and Williams (1988), we extend the backpropagation algorithm to associative reinforcement learning. Start with a \\\"garden variety\\\" backpropagation network: A vector i of n binary input units propagates\\nthrough zero or more layers of hidden units, ultimately reaching a vector 8 of m\\nsigmoid units, each taking continuous values in the range (0,1). Interpret each 8j\\nas the probability that an associated random bit OJ takes on value 1. Let us call\\nthe continuous, deterministic vector 8 the search vector to distinguish it from the\\nstochastic binary output vector o.\\nGiven an input vector, we forward propagate to produce a search vector 8, and\\nthen perform m independent Bernoulli trials to produce an output vector o. The\\ni - 0 pair is evaluated by the reinforcement function and reward or punishment\\nensues. Suppose reward occurs. We therefore want to make 0 more likely given i.\\nBackpropagation will do just that if we take 0 as the desired target to produce an\\nerror vector (0 - 8) and adjust weights normally.\\nNow suppose punishment occurs, indicating 0 does not correspond with i. By choice\\nof error vector, backpropagation allows us to push the search vector in any direction;\\nwhich way should we go? In absence of problem-specific information, we cannot pick\\nan appropriate direction with certainty. Any decision will involve assumptions. A\\nvery minimal \\\"don't be like 0\\\" assumption-employed in Anderson (1986), Williams\\n(1988), and Ackley (1989)-pushes s directly away from 0 by taking (8 - 0) as the\\nerror vector. A slightly stronger \\\"be like not-o\\\" assumption-employed in Barto &\\nAnandan (1985) and Ackley (1987)-pushes s directly toward the complement of 0\\nby taking ((1 - 0) - 8) as the error vector. Although the two approaches always\\nagree on the signs of the error terms, they differ in magnitudes. In this work,\\nwe explore the second possibility, embodied in an algorithm called complementary\\nreinforcement back-propagation ( CRBP).\\nFigure 1 summarizes the CRBP algorithm. The algorithm in the figure reflects three\\nmodifications to the basic approach just sketched. First, in step 2, instead of using\\nthe 8j'S directly as probabilities, we found it advantageous to \\\"stretch\\\" the values\\nusing a parameter v. When v < 1, it is not necessary for the 8i'S to reach zero or\\none to produce a deterministic output. Second, in step 6, we found it important\\nto use a smaller learning rate for punishment compared to reward. Third, consider\\nstep 7: Another forward propagation is performed, another stochastic binary output vector 0* is generated (using the procedure from step 2), and 0* is compared\\nto o. If they are identical and punishment occurred, or if they are different and\\nreward occurred, then another error vector is generated and another weight update\\nis performed. This loop continues until a different output is generated (in the case\\nof failure) or until the original output is regenerated (in the case of success). This\\nmodification improved performance significantly, and added only a small percentage\\nto the total number of weight updates performed.\\n\\n551\\n\\n\\f552\\n\\nAckley and Littman\\n\\nO. Build a back propagation network with input dimensionality n and output\\ndimensionality m. Let t = 0 and te = O.\\n1. Pick random i E 2n and forward propagate to produce a/s.\\n2. Generate a binary output vector o. Given a uniform random variable ~ E [0,1]\\nand parameter 0 < v < 1,\\nOJ\\n\\n=\\n\\n{1,\\n\\n0,\\n\\nif(sj - !)/v+! ~ ~j\\notherwise.\\n\\n3. Compute reinforcement r = f(i,o). Increment t. If r < 0, let te = t.\\n4. Generate output errors ej. If r > 0, let tj = OJ, otherwise let tj = 1- OJ. Let\\nej = (tj - sj)sj(l- Sj).\\n5. Backpropagate errors.\\n6. Update weights. 1:::..Wjk = 1]ekSj, using 1] = 1]+ if r ~ 0, and 1] = 1]- otherwise,\\nwith parameters 1]+,1]- > o.\\n7. Forward propagate again to produce new Sj's. Generate temporary output\\nvector 0*. If (r > 0 and 0* #- 0) or (r < 0 and 0* = 0), go to 4.\\n8. If te ~ t, exit returning te, else go to 1.\\n\\nFigure 1: Complementary Reinforcement Back Propagation-CRBP\\n\\n2\\n\\nON-LINE GENERALIZATION\\n\\nWhen there are many possible outputs and correct pairings are rare, the computational cost associated with the search for the correct answers can be profound.\\nThe search for correct pairings will be accelerated if the search strategy can effectively generalize the reinforcement received on one input to others. The speed of\\nan algorithm on a given problem relative to non-generalizing algorithms provides a\\nmeasure of generalization that we call on-line generalization.\\nO. Let z be an array of length 2n. Set the z[i] to random numbers from 0 to\\n2m - 1. Let t = te = O.\\n1. Pick a random input i E 2n.\\n2. Compute reinforcement r = f(i, z[i]). Increment t.\\n3. If r < 0 let z[i] = (z[i] + 1) mod 2m , and let te = t.\\n4. If te <t:: t exit returning t e, else go to 1.\\n\\nFigure 2: The Table Lookup Reference Algorithm Tref(f, n, m)\\nConsider the table-lookup algorithm Tref(f, n, m) summarized in Figure 2. In this\\nalgorithm, a separate storage location is used for each possible input. This prevents\\nthe memorization of one i - 0 pair from interfering with any other. Similarly,\\nthe selection of a candidate output vector depends only on the slot of the table\\ncorresponding to the given input. The learning speed of T ref depends only on the\\ninput and output dimensionalities and the number of correct outputs associated\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\nwith each input. When a problem possesses n input bits and n output bits, and\\nthere is only one correct output vector for each input vector, Tre{ runs in about 4n\\ntime (counting each input-output judgment as one.) In such cases one expects to\\ntake at least 2n - 1 just to find one correct i - 0 pair, so exponential time cannot be\\navoided without a priori information. How does a generalizing algorithm such as\\nCRBP compare to Trer?\\n\\n3\\n\\nSIMULATIONS ON SCALABLE PROBLEMS\\n\\nWe have tested CRBP on several simple problems designed to offer varying degrees\\nand types of generalization. In all of the simulations in this section, the following\\ndetails apply: Input and output bit counts are equal (n). Parameters are dependent\\non n but independent of the reinforcement function f. '7+ is hand-picked for each\\nn,l 11- = 11+/10 and II = 0.5. All data points are medians of five runs. The stopping\\ncriterion te ~ t is interpreted as te +max(2000, 2n+l) < t. The fit lines in the figures\\nare least squares solutions to a x bn , to two significant digits.\\nAs a notational convenience, let c = ~\\n\\n3.1\\n\\nn\\n\\nE ij\\n\\n;=1\\n\\n-\\n\\nthe fraction of ones in the input.\\n\\nn-MAJORlTY\\n\\nConsider this \\\"majority rules\\\" problem: [if c > ~ then 0 = In else 0 = on]. The i-o\\nmapping is many-to-l. This problem provides an opportunity for what Anderson\\n(1986) called \\\"output generalization\\\": since there are only two correct output states,\\nevery pair of output bits are completely correlated in the cases when reward occurs.\\n\\nG)\\n\\n'iii\\nu\\nrn\\n\\nC)\\n\\n0\\n\\n::::.\\nG)\\n\\nE\\n\\n;\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n\\nTable\\n\\nD\\n\\nCRBP n-n-n\\n\\n+ CRBP n-n\\n\\n10 3\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n456\\n\\n78\\n\\n91011121314\\n\\nn\\nFigure 3: The n-majority problem\\n\\nFigure 3 displays the simulation results. Note that although Trer is faster than\\nCRBP at small values of n, CRBP's slower growth rate (1.6n vs 4.2n ) allows it to\\ncross over and begin outperforming Trer at about 6 bits. Note also--in violation of\\n1 For n = 1 to 12. we used '1+\\n0.219. 0.170. 0.121}.\\n\\n= {2.000. 1.550. 1.130.0.979.0.783.0.709.0.623.0.525.0.280.\\n\\n553\\n\\n\\f554\\n\\nAckley and Littman\\n\\nsome conventional wisdom-that although n-majority is a linearly separable problem, the performance of CRBP with hidden units is better than without. Hidden\\nunits can be helpful--even on linearly separable problems-when there are opportunities for output generalization.\\n\\n3.2\\n\\nn-COPY AND THE 2k -ATTRACTORS FAMILY\\n\\nAs a second example, consider the n-copy problem: [0 = i]. The i-o mapping is now\\n1-1, and the values of output bits in rewarding states are completely uncorrelated,\\nbut the value of each output bit is completely correlated with the value of the\\ncorresponding input bit. Figure 4 displays the simulation results. Once again, at\\n\\nG)\\n\\n'ii\\n\\ntA\\nQ\\n0\\n\\n::::.\\nG)\\n\\n-\\n\\n.5\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n150*2.0I\\\\n\\n\\nD\\n\\n10 3\\n10 2\\n\\n12*2.2I\\\\n\\n\\n+\\n\\nTable\\nCRBP n-n-n\\nCRBP n-n\\n\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 4: The n-copy problem\\nlow values of n, Trer is faster, but CRBP rapidly overtakes Trer as n increases. In\\nn-copy, unlike n-majority, CRBP performs better without hidden units.\\nThe n-majority and n-copy problems are extreme cases of a spectrum. n-majority\\ncan be viewed as a \\\"2-attractors\\\" problem in that there are only two correct\\noutputs-all zeros and all ones-and the correct output is the one that i is closer\\nto in hamming distance. By dividing the input and output bits into two groups\\nand performing the majority function independently on each group, one generates\\na \\\"4-aUractors\\\" problem. In general, by dividing the input and output bits into\\n1 ~ Ie ~ n groups, one generates a \\\"2i:-attractors\\\" problem. When Ie = 1, nmajority results, and when Ie n, n-copy results.\\n\\n=\\n\\nFigure 5 displays simulation results on the n = 8-bit problems generated when Ie is\\nvaried from 1 to n. The advantage of hidden units for low values of Ie is evident,\\nas is the advantage of \\\"shortcut connections\\\" (direct input-to-output weights) for\\nlarger values of Ie. Note also that combination of both hidden units and shortcut\\nconnections performs better than either alone.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n105~--------------------------------~\\n\\nCASP 8-10-8\\n-+- CASP 8-8\\n.... CASP 8-10-Sls\\n-0-\\n\\n... Table\\n\\n3\\n\\n2\\n\\n1\\n\\n5\\n\\n4\\n\\n7\\n\\n6\\n\\n8\\n\\nk\\n\\nFigure 5: The 21:- attractors family at n = 8\\n\\n3.3\\n\\nn-EXCLUDED MIDDLE\\n\\nAll of the functions considered so far have been linearly separable. Consider this\\n\\\"folded majority\\\" function: [if\\n< c < then 0 on else 0 In]. Now, like\\nn-majority, there are only two rewarding output states, but the determination of\\nwhich output state is correct is not linearly separable in the input space. When\\nn = 2, the n-excluded middle problem yields the EQV (i.e., the complement of\\nXOR) function, but whereas functions such as n-parity [if nc is even then 0\\non\\nelse 0 = In] get more non-linear with increasing n, n-excluded middle does not.\\n\\ni\\n\\ni\\n\\n=\\n\\n=\\n\\n=\\n\\n107~------------------------------~~\\n\\n-\\n\\n10 6\\n10 5\\n\\nD)\\n\\n10 4\\n10 3\\n\\nI)\\n\\n'ii\\nu\\nf)\\n\\n.2\\n\\nI)\\n\\nE\\n\\n:::\\n\\nx\\nc\\n\\n17oo*1.6\\\"n\\n\\nTable\\n\\nCRSP n-n-n/s\\n\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 6: The n-excluded middle problem\\nFigure 6 displays the simulation results. CRBP is slowed somewhat compared to\\nthe linearly separable problems, yielding a higher \\\"cross over point\\\" of about 8 bits.\\n\\n555\\n\\n\\f556\\n\\nAckley and Littman\\n\\n4\\n\\nSTRUCTURING DEGENERATE OUTPUT SPACES\\n\\nAll of the scaling problems in the previous section are designed so that there is\\na single correct output for each possible input. This allows for difficult problems\\neven at small sizes, but it rules out an important aspect of generalizing algorithms\\nfor associative reinforcement learning: If there are multiple satisfactory outputs\\nfor given inputs, a generalizing algorithm may impose structure on the mapping it\\nproduces.\\nWe have two demonstrations of this effect, \\\"Bit Count\\\" and \\\"Inverse Arithmetic.\\\"\\nThe Bit Count problem simply states that the number of I-bits in the output should\\nequal the number of I-bits in the input. When n = 9, Tref rapidly finds solutions\\ninvolving hundreds of different output patterns. CRBP is slower--especially with\\nrelatively few hidden units-but it regularly finds solutions involving just 10 output\\npatterns that form a sequence from 09 to 19 with one bit changing per step.\\n0+Ox4=0\\n1+0x4=1\\n2+0x4=2\\n3+0x4=3\\n\\n0+2x4=8\\n1+2x4=9\\n2 + 2 x 4 = 10\\n3+2x4=11\\n\\n4+0x4=4 4+ 2 x 4 =\\n5+0x4=5 5 + 2 x 4 =\\n6+0x4=6 6 + 2 x 4 =\\n7+0x4=7 7 + 2 x 4 =\\n\\n12\\n13\\n14\\n15\\n\\n2+2-4=0 2+2+4=8\\n3+2-4=1 3+2+4=9\\n2+2+4=2 2 + 2 x 4 = 10\\n3+2+4=3 3+2x4=1l\\n6+2-4=4\\n7+2-4=5\\n6+2+4=6\\n7+2-.;-4=7\\n\\n6+\\n7+\\n6+\\n7+\\n\\n2+ 4 =\\n2+ 4 =\\n2x4=\\n2x4=\\n\\n0+4 x 4 = 16 0+6 x 4 =\\n1+4x4=17 1 + 6 x 4 =\\n2 + 4 x 4 = 18 2 + 6 x 4 =\\n3 +4 x 4 = 19 3 + 6 x 4 =\\n\\n24\\n25\\n26\\n27\\n\\n4+4\\n5+ 4\\n6+ 4\\n7+ 4\\n\\n=\\n=\\n=\\n=\\n\\n28\\n29\\n30\\n31\\n24\\n25\\n26\\n27\\n\\nx\\nx\\nx\\nx\\n\\n4=\\n4=\\n4=\\n4=\\n\\n6+ 6 + 4 =\\n7+6+4=\\n2+ 4 x 4 =\\n3+ 4 x 4=\\n\\n12 4 x 4 +\\n13 5 + 4 x\\n14 6 + 4 x\\n15 7 +4 x\\n\\n4=\\n4=\\n4\\n4=\\n\\n=\\n\\n20 4 + 6 x\\n21 5 + 6 x\\n22 6 + 6 x\\n23 7 + 6 x\\n\\n4\\n4\\n4\\n4\\n\\n16\\n17\\n18\\n19\\n\\n0+6 x\\n1+ 6 x\\n2+ 6x\\n3+ 6x\\n\\n4=\\n4=\\n4=\\n4=\\n\\n20\\n21\\n22\\n23\\n\\n4+\\n5+\\n6+\\n7+\\n\\n4 = 28\\n4 = 29\\n4 30\\n4 = 31\\n\\n6\\n6\\n6\\n6\\n\\nx\\nx\\nx\\nx\\n\\n=\\n\\nFigure 7: Sample CRBP solutions to Inverse Arithmetic\\n\\nThe Inverse Arithmetic problem can be summarized as follows: Given i E 25 , find\\n:1:, y, z E 23 and 0, <> E {+(OO)' -(01)' X (10)' +(11)} such that :I: oy<>z = i. In all there are\\n13 bits of output, interpreted as three 3-bit binary numbers and two 2-bit operators,\\nand the task is to pick an output that evaluates to the given 5-bit binary input\\nunder the usual rules: operator precedence, left-right evaluation, integer division,\\nand division by zero fails.\\nAs shown in Figure 7, CRBP sometimes solves this problem essentially by discovering positional notation, and sometimes produces less-globally structured solutions,\\nparticularly as outputs for lower-valued i's, which have a wider range of solutions.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n5\\n\\nCONCLUSIONS\\n\\nSome basic concepts of supervised learning appear in different guises when the\\nparadigm of reinforcement learning is applied to large output spaces. Rather than\\na \\\"learning phase\\\" followed by a \\\"generalization test,\\\" in reinforcement learning\\nthe search problem is a generalization test, performed simultaneously with learning.\\nInformation is put to work as soon as it is acquired.\\nThe problem of of \\\"overfitting\\\" or \\\"learning the noise\\\" seems to be less of an issue,\\nsince learning stops automatically when consistent success is reached. In experiments not reported here we gradually increased the number of hidden units on\\nthe 8-bit copy problem from 8 to 25 without observing the performance decline\\nassociated with \\\"too many free parameters.\\\"\\nThe 2 k -attractors (and 2 k -folds-generalizing Excluded Middle) families provide\\na starter set of sample problems with easily understood and distinctly different\\nextreme cases.\\nIn degenerate output spaces, generalization decisions can be seen directly in the\\ndiscovered mapping. Network analysis is not required to \\\"see how the net does it.\\\"\\nThe possibility of ultimately generating useful new knowledge via reinforcement\\nlearning algorithms cannot be ruled out.\\nReferences\\nAckley, D.H. (1987) A connectionist machine for genetic hillclimbing. Boston, MA: Kluwer\\nAcademic Press.\\nAckley, D.H. (1989) Associative learning via inhibitory search. In D.S. Touretzky (ed.),\\nAdvances in Neural Information Processing Systems 1, 20-28. San Mateo, CA: Morgan\\nKaufmann.\\nAllen, R.B. (1989) Developing agent models with a neural reinforcement technique. IEEE\\nSystems, Man, and Cybernetics Conference. Cambridge, MA.\\nAnderson, C.W. (1986) Learning and problem solving with multilayer connectionist systems. University of Mass. Ph.D. dissertation. COINS TR 86-50. Amherst, MA.\\nBarto, A.G. (1985) Learning by statistical cooperation of self-interested neuron-like computing elements. Human Neurobiology, 4:229-256.\\nBarto, A.G., & Anandan, P. (1985) Pattern recognizing stochastic learning automata.\\nIEEE Transactions on Systems, Man, and Cybernetics, 15, 360-374.\\nRumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986) Learning representations by backpropagating errors. Nature, 323, 533-536.\\nSutton, R.S. (1984) Temporal credit assignment in reinforcement learning. University of\\nMass. Ph.D. dissertation. COINS TR 84-2. Amherst, MA.\\nWilliams, R.J. (1988) Toward a theory of reinforcement-learning connectionist systems.\\nCollege of Computer Science of Northeastern University Technical Report NU-CCS-88-3.\\nBoston, MA.\\n\\n557\\n\\n\\f\",\n          \"Dynamics of Supervised Learning with\\nRestricted Training Sets and Noisy Teachers\\n\\nA.C.C. Coolen\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ntcoolen@mth.kc1.ac.uk\\n\\nC.W.H.Mace\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ncmace@mth.kc1.ac.uk\\n\\nAbstract\\nWe generalize a recent formalism to describe the dynamics of supervised\\nlearning in layered neural networks, in the regime where data recycling\\nis inevitable, to the case of noisy teachers. Our theory generates reliable\\npredictions for the evolution in time of training- and generalization errors, and extends the class of mathematically solvable learning processes\\nin large neural networks to those situations where overfitting can occur.\\n\\n1 Introduction\\nTools from statistical mechanics have been used successfully over the last decade to study\\nthe dynamics of learning in layered neural networks (for reviews see e.g. [1] or [2]). The\\nsimplest theories result upon assuming the data set to be much larger than the number\\nof weight updates made, which rules out recycling and ensures that any distribution of\\nrelevance will be Gaussian. Unfortunately, both in terms of applications and in terms of\\nmathematical interest, this regime is not the most relevant one. Most complications and\\npeculiarities in the dynamics of learning arise precisely due to data recycling, which creates\\nfor the system the possibility to improve performance by memorizing answers rather than\\nby learning an underlying rule. The dynamics of learning with restricted training sets was\\nfirst studied analytically in [3] (linear learning rules) and [4] (systems with binary weights).\\nThe latter studies were ahead of their time, and did not get the attention they deserved just\\nbecause at that stage even the simpler learning dynamics without data recycling had not\\nyet been studied. More recently attention has moved back to the dynamics of learning\\nin the recycling regime. Some studies aimed at developing a general theory [5, 6, 7],\\nsome at finding exact solutions for special cases [8]. All general theories published so far\\nhave in common that they as yet considered realizable scenario's: the rule to be learned\\nwas implementable by the student, and overfitting could not yet occur. The next hurdle is\\nthat where restricted training sets are combined with unrealizable rules. Again some have\\nturned to non-typical but solvable cases, involving Hebbian rules and noisy [9] or 'reverse\\nwedge' teachers [10]. More recently the cavity method has been used to build a general\\ntheory [11] (as yet for batch learning only). In this paper we generalize the general theory\\nlaunched in [6,5,7], which applies to arbitrary learning rules, to the case of noisy teachers.\\nWe will mirror closely the presentation in [6] (dealing with the simpler case of noise-free\\nteachers), and we refer to [5, 7] for background reading on the ideas behind the formalism.\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n238\\n\\n2 Definitions\\nAs in [6, 5] we restrict ourselves for simplicity to perceptrons. A student perceptron operates a linear separation, parametrised by a weight vector J E iRN :\\nS:{-I,I}N -t{-I,I}\\n\\nS(e) = sgn[J?e]\\n\\nIt aims to emulate a teacher o~erating a similar rule, which, however, is characterized by a\\nvariable weight vector BE iR ,drawn at random from a distribution P(B) such as\\nP(B) = >'6[B+B*]\\n\\noutput noise:\\n\\n+ (1->')6[B-B*]\\n\\n(1)\\n\\nP(B) = [~~/NrN e- tN (B-B')2/E2\\n(2)\\nThe parameters>. and ~ control the amount of teacher noise, with the noise-free teacher\\nB = B* recovered in the limits>. -t 0 and ~ -t O. The student modifies J iteratively, using\\nexamples of input vectors which are drawn at random from a fixed (randomly composed)\\nE {-I, I}N with a> 0, and the corresponding\\ntraining set containing p = aN vectors\\nvalues of the teacher outputs. We choose the teacher noise to be consistent, i.e. the answer\\nwill remain the same when that particular question\\ngiven by the teacher to a question\\nre-appears during the learning process. Thus T(e?) = sgn[BJL . e], with p teacher weight\\nvectors BJL, drawn randomly and independently from P(B), and we generalize the training\\nl , B l ), . .. , (e, BP)}. Consistency of teacher noise is natural\\nset accordingly to jj =\\nin terms of applications, and a prerequisite for overfitting phenomena. Averages over the\\ntraining set will be denoted as ( ... ) b; averages over all possible input vectors E {-I, I}N\\nas ( ... )e. We analyze two classes of learning rules, of the form J (? + 1) = J (?) + f).J (?):\\n\\nGaussian weight noise:\\n\\ne\\n\\ne\\n\\ne\\n\\nHe\\n\\ne\\n\\n= 11 {e(?) 9 [J(?)?e(?), B(?)?e(?)] - ,J(?) }\\nf).J(?) = 11 {(e 9 [J(?)?e, B?eDl> - ,J(m) }\\n\\non-line:\\n\\nf).J(?)\\n\\nbatch :\\n\\n(3)\\n\\nIn on-line learning one draws at each step ? a question/answer pair (e (?), B (?)) at random from the training set. In batch learning one iterates a deterministic map which is an\\naverage over all data in the training set. Our performance measures are the training- and\\ngeneralization errors, defined as follows (with the step function O[x > 0] = 1, O[x < 0] = 0):\\nEt(J)\\n\\n= (O[-(J ?e)(B ?em b\\n\\nEg(J)\\n\\n= (O[-(J ?e)(B* ?e)])e\\n\\n(4)\\n\\nWe introduce macroscopic observables, taylored to the present problem, generalizing [5, 6]:\\nQ[J]=J 2,\\nR[J]=J?B*,\\nP[x,y,z;J]=(6[x-J?e]6[y-B*?e]6[z-B?eDl> (5)\\nAs in [5, 6] we eliminate technical subtleties by assuming the number of arguments (x, y, z)\\nfor which P[x, y, z; J] is evaluated to go to infinity after the limit N -t 00 has been taken.\\n\\n3 Derivation of Macroscopic Laws\\nUpon generalizing the calculations in [6, 5], one finds for on-line learning:\\n\\n!\\n!\\n\\nQ = 2'f} !dXdydZ P[x, y, z] xg[x, z] - 2'f},Q + 'f}2!dXdYdZ P[x, y, z] g2[x, z]\\n\\n(6)\\n\\nR = 'f} !dXdydZ P[x, y, z] y9[x, z]- 'f},R\\n\\n(7)\\n\\n:t\\n\\nP[x, y, z] =\\n\\n~\\n\\n!\\n\\ndx' P[x', y, z] {6[x-x' -'f}G[x', z]] -6[x-x']}\\n\\n-'f}! / dx'dy'dz' / dx'dy'dz'9[x', z]A[x, y, z; x',y', z']\\n\\n1\\n+'i'f}2\\n\\n!\\n\\n+ 'f}, :x\\n\\nEP2P[x, y, z]\\ndx'dy'dz' P[x', y', z']92[x', z'] 8x\\n\\n{xP[x , y, z]}\\n\\n(8)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n239\\n\\nThe complexity of the problem is concentrated in a Green's function:\\nA[x, y, Zj x', y', z'] = lim\\nN-+oo\\n\\n(( ([1-6ee , ]6[x-J?e]6[y-B*?e]6[z-B?e] (e?e')6[x' -J?e']6[y' - B*?e']6[y' - B?e'])i?i> )QW;t\\n\\nJ\\n\\nIt involves a conditional average of the form (K[J])QW;t = dJ Pt(JIQ,R,P)K[J], with\\nPt(J) 6[Q-Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] -P[x, y, Zj J]]\\nPt(JIQ,R,P)\\nJdJ Pt(J) 6[Q - Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] - P[x, y, z; J]]\\n\\n=\\n\\nin which Pt (J) is the weight probability density at time t. The solution of (6,7,8) can be\\nused to generate the N -+ 00 performance measures (4) at any time:\\nEt\\n\\n=/\\n\\ndxdydz P[x, y, z]O[-xz]\\n\\nEg\\n\\n= 11\\\"-1 arccos[RIVQ]\\n\\n(9)\\n\\nExpansion of these equations in powers of\\\"\\\" and retaining only the terms linear in \\\"\\\" gives\\nthe corresponding equations describing batch learning. So far this analysis is exact.\\n\\n4\\n\\nClosure of Macroscopic Laws\\n\\nAs in [6, 5] we close our macroscopic laws (6,7,8) by making the two key assumptions\\nunderlying dynamical replica theory:\\n(i) For N -+ 00 our macroscopic observables obey closed dynamic equations.\\n(ii) These equations are self-averaging with respect to the specific realization of D.\\n\\n(i) implies that probability variations within {Q, R, P} subshells are either absent or irrelevant to the macroscopic laws. We may thus make the simplest choice for Pt (J IQ, R, P):\\nPt(JIQ,R,P) -+ 6[Q-Q[J]] 6[R-R[J]]\\n\\nII 6[P[x,y,z]-P[x,y,ZjJ]]\\n\\n(10)\\n\\nxyz\\n\\nThe procedure (10) leads to exact laws if our observables {Q, R, P} indeed obey closed\\nequations for N -+ 00. It is a maximum entropy approximation if not. (ii) allows us\\nto average the macroscopic laws over all training sets; it is observed in simulations, and\\nproven using the formalism of [4]. Our assumptions (10) result in the closure of (6,7,8),\\nsince now the Green's function can be written in terms of {Q, R, Pl. The final ingredient\\nof dynamical replica theory is doing the average of fractions with the replica identity\\n\\n/ JdJ W[JID]GIJID])\\n\\n\\\\\\n\\nJdJ W[JID]\\n\\n= lim\\nsets\\n\\n/dJ I\\n\\n???\\n\\ndJn (G[J 1 ID]\\n\\nn-+O\\n\\nIT\\n\\nW[JO<ID])sets\\n\\na=1\\n\\nOur problem has been reduced to calculating (non-trivial) integrals and averages. One\\nfinds that P[x, y, z] P[x, zly]P[y] with Ply] (211\\\")-!exp[-!y 21With the short-hands\\nDy = P[y]dy and (f(x, y, z)) = Dydxdz P[x, zly]f(x, y, z) we can write the resulting\\nmacroscopic laws, for the case of output noise (1), in the following compact way:\\n\\n=\\n\\nd\\n\\ndt Q = 2\\\",(V - ,Q)\\n\\n[)\\n\\n[)tP[x,zly] =\\n\\n=\\n\\nJ\\n\\n+ rJ2 Z\\n\\nd\\n\\ndtR = \\\",(W - ,R)\\n\\n(11)\\n\\n1 [)x[)22P[x,zIY]\\na1/dx'P[x',zly] {6[x-x'-\\\",G[x',z]]-6[x-x'] }+2\\\",2Z\\n\\n-\\\",:x {P[x,zly]\\n\\n[U(x-RY)+Wy-,x+[V-RW-(Q-R2)U]~[x,y,z])}\\n\\n(12)\\n\\nwith\\n\\nU = (~[x, y, z]9[x, z]),\\n\\nv = (x9[x, z]),\\n\\nW = (y9[x, z]),\\n\\nZ = (9 2[x, z])\\n\\nThe solution of (12) is at any time of the following form:\\n\\nP[x,zly]\\n\\n= (1-,x)6[y-z]P+[xly] + ,x6[y+z]P-[xly]\\n\\n(13)\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n240\\n\\nFinding the function <I> [x, y, z] (in replica symmetric ansatz) requires solving a saddle-point\\nproblem for a scalar observable q and two functions M?[xly]. Upon introducing\\n\\nB = . . :. V. .,. .q.,-Q___R,-2\\nQ(I-q)\\n(with Jdx M?[xly]\\n\\nJdx M?[xly]eBxs J[x, y]\\nJdx M?[xly]eBxs\\n\\n(f[x, y])? =\\n*\\n\\n= 1 for all y) the saddle-point equations acquire the fonn\\np?[Xly] =\\n\\nfor all X, y :\\n\\n((x-Ry)2) + (qQ-R 2)[I-!:.]\\na\\n\\n!\\n\\nDs (O[X -xl);\\n\\n2 !DYDS S[(I-A)(X); + A(X);]\\n= qQ+Q-2R\\n..jqQ_R2\\n\\n(14)\\n(15)\\n\\nThe equations (14) which detennine M?[xly] have the same structure as the corresponding\\n(single) equation in [5, 6], so the proofs in [5, 6] again apply, and the solutions M?[xly],\\ngiven a q in the physical range q E [R2/Q, 1], are unique. The function <I> [x, y, z] is then\\ngiven by\\n<I> [X,\\n\\ny, z]\\n\\n=!\\n\\nDs s\\n{(I-A)O[Z-y](o[X -x)); + AO[Z+Y](o[X -xl);}\\n..jqQ_R2 P[X, zly]\\n(16)\\n\\nWorking out predictions from these equations is generally CPU-intensive, mainly due to\\nthe functional saddle-point equation (14) to be solved at each time step. However, as in [7]\\none can construct useful approximations of the theory, with increasing complexity:\\n\\n(i) Large a approximation (giving the simplest theory, without saddle-point equations)\\n(ii) Conditionally Gaussian approximation for M[xly] (with y-dependent moments)\\n(iii) Annealed approximation of the functional saddle-point equation\\n\\n5 Benchmark Tests: The Limits a --+ 00 and ,\\\\ --+ 0\\nWe first show that in the limit a --+ 00 our theory reduces to the simple (Q, R) formalism\\nof infinite training sets, as worked out for noisy teachers in [12]. Upon making the ansatz\\n\\np?[xly] = P[xly] = [27r(Q-R 2)]-t e- t [x- Rv]2/(Q-R 2)\\n\\n(17)\\n\\none finds\\n\\n<I>[x,y,Z] = (x-Ry)/(Q-R 2)\\n\\nM?[xly] = P[xly],\\n\\nInsertion of our ansatz into (12), followed by rearranging of terms and usage of the above\\nexpression for <I> [x, y, z], shows that (12) is satisfied. The remaining equations (11) involve\\nonly averages over the Gaussian distribution (17), and indeed reduce to those of [12]:\\n\\n~! Q =\\n\\n(I-A) { 2(x9[x, y))\\n1 d\\n--d R\\n1} t\\n\\n+ 1}{92[x, y)) } + A {2(x9[x,-y)) + 1}(92[x,-y)) } - 2,Q\\n\\n= (I-A)(y9[x,y)) + A(y9[x,-yl) -,R\\n\\nNext we turn to the limit A --+ 0 (restricted training sets & noise-free teachers) and show that\\nhere our theory reproduces the fonnalism of [6,5]. Now we make the following ansatz:\\n\\nP+[xly] = P[xly],\\n\\nP[x, zly]\\n\\n= o[z-y]P[xIY]\\n\\n(18)\\n\\nInsertion shows that for A = 0 solutions of this fonn indeed solve our equations, giving\\n<p[x, y, z]--+ <I> [x, y] and M+[xly]\\nM[xly), and leaving us exactly with the fonnalism\\nof [6, 5] describing the case of noise-free teachers and restricted training sets (apart from\\nsome new tenns due to the presence of weight decay, which was absent in [6, 5]).\\n\\n=\\n\\n\\f241\\n\\nSupervised Learning with Restricted Training Sets\\n0. , r------~--__,\\n\\n0..4\\n\\n~-------_____I\\n\\n0..4\\n\\n11>=0.'\\n\\n0..3\\n\\na=4\\n\\n0. ,\\n\\n0..0.\\n\\n--\\n\\n, 0.\\n\\n0.2\\n\\n_ __ ___ _____ _\\n\\na= 1\\n\\n0;=1\\n\\n------- ---- -- --- -\\n\\n0.\\n\\n0;=2\\n\\n=-=\\n-\\n\\n0;=2\\n\\n- - ----- -\\n\\na=4\\na=4\\n\\n= =-=\\n--=-=--=-=--=-=-=-- -=-=-_oed\\n\\na=4\\n\\n,\\n\\n0;=2\\n\\n':::::========:::j\\n\\n0..3\\n\\n-- - ----\\n\\n0;=1\\n\\n:::---- - -----1\\n\\n0;=2\\n\\n0..2\\n\\n11>=0.'\\n\\n~-------~\\n\\n0;=1\\n\\n0.,\\n\\n11>=0,\\n\\n\\\"\\n\\n,\\n\\nno. I\\n\\n0.\\n\\n, 0.\\n\\n\\\"\\n\\nFigure 1: On-line Hebbian learning: conditionally Gaussian approximation versus exact\\nsolution in [9] (.,., = 1, ,X = 0.2). Left: \\\"I = 0.1, right: \\\"I = 0.5. Solid lines: approximated\\ntheory, dashed lines: exact result. Upper curves: Eg as functions of time (here the two\\ntheories agree), lower curves: E t as functions of time.\\n\\n6\\n\\nBenchmark Tests: Hebbian Learning\\n\\nThe special case of Hebbian learning, i.e. Q[x, z] = sgn(z), can be solved exactly at any\\ntime, for arbitrary {a, ,x, \\\"I} [9], providing yet another excellent benchmark for our theory.\\nFor batch execution of Hebbian learning the macroscopic laws are obtained upon expanding\\n(11,12) and retaining only those terms which are linear in.,.,. All integrations can now be\\ndone and all equations solved explicitly, resulting in U =0, Z = 1, W = (I-2,X)J2/7r, and\\n\\nQ\\n\\n= Qo e-2rryt +\\n\\n2Ro(I-2'x) e-17\\\"Yt[I_e-rrrt]\\n\\\"I\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I-e- 17 \\\"Y tF\\n\\\"12\\n\\nR = Ro e- 17\\\"Y t +(I-2'x)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\nq = [aR2+(I_e- 17\\\"Yt)2 i'l]/aQ\\np?[xIY] = [27r(Q-R2)] -t e-tlz-RH sgn(y)[1-e-\\\"..,t]/a\\\"Y]2/(Q-R2)\\n(19)\\nFrom these results, in tum, follow the performance measures Eg = 7r- 1 arccos[ R/ JQ) and\\n\\nE = ! - !(1-,X)!D\\n2\\n\\nt\\n\\n2\\n\\nerf[IYIR+[I-e- 77\\\"Y t ]/a\\\"l] + !,X!D erf[IYIR-[I-e- 17\\\"Y t ]/a\\\"l]\\nY\\nJ2(Q-R2)\\n2\\ny\\nJ2(Q-R2)\\n\\nComparison with the exact solution, calculated along the lines of [9] or, equivalently, obtained upon putting t ?\\nin [9], shows that the above expressions are all exact.\\n\\n.,.,-2\\n\\nFor on-line execution we cannot (yet) solve the functional saddle-point equation in general.\\nHowever, some analytical predictions can still be extracted from (11,12,13):\\n\\nQ = Qo e-217\\\"Yt + 2Ro(I-2,X) e-77\\\"Yt[I_e-17\\\"Yt]\\n\\\"I\\n\\nR = Ro e- 17\\\"Y t + (I-2,X)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\n\\nJ\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I_e- 17\\\"Y t ]2\\n\\\"12\\n\\n+ !L[I_e- 217\\\"Y t ]\\n2\\\"1\\n\\ndx xP?[xIY] = Ry ? sgn(y)[I-e- 17\\\"Y t ]/a\\\"l\\n\\nwith U =0, W = (I-2,X)J2/7r, V = W R+[I-e- 17\\\"Y t ]/a\\\"l, and Z = 1. Comparison with the\\nresults in [9] shows that the above expressions, and thus also that of E g , are all fully exact,\\nat any time. Observables involving P[x, y, z] (including the training error) are not as easily\\nsolved from our equations. Instead we used the conditionally Gaussian approximation\\n(found to be adequate for the noiseless Hebbian case [5, 6, 7]). The result is shown in\\nfigure 1. The agreement is reasonable, but significantly less than that in [6]; apparently\\nteacher noise adds to the deformation of the field distribution away from a Gaussian shape.\\n\\n\\f242\\n\\nA. C. C. Coolen and C. W H. Mac\\n\\n~\\n\\n0.6\\n\\n000000\\n\\n0.4\\n\\n0.4\\n\\nE\\n\\n~\\n\\n0.2\\n\\nI\\ni\\n0.0\\n\\n0\\n\\n4\\n\\n2\\n\\n6\\n\\n10\\n\\n0.0\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\nX\\n\\n0.6\\n\\nf\\n\\n0.4\\n\\n0.4 [\\n\\nE\\n0.2\\n\\n0.2\\n\\n0.0\\n\\nL-o!i6iIII.\\\"\\\"\\\"\\\"\\\"',-\\\"--~_~~_ _--'\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\n\\n2\\n\\n3\\n\\nX\\n\\n,=\\n\\nFigure 2: Large a approximation versus numerical simulations (with N = 10,000), for\\n0 and A = 0.2. Top row: Perceptron rule, with.,., = ~. Bottom row: Adatron rule,\\nwith.,., = ~. Left: training errors E t and generalisation errors Eg as functions of time, for\\naE {~, 1, 2}. Lines: approximated theory, markers: simulations (circles: E t , squares: Eg) .\\nRight: joint distributions for student field and teacher noise p?[x] = dy P[x, y, z = ?y]\\n(upper: P+[x], lower: P-[x]). Histograms: simulations, lines: approximated theory.\\n\\nJ\\n\\n7\\n\\nNon-Linear Learning Rules: Theory versus Simulations\\n\\nIn the case of non-linear learning rules no exact solution is known against which to test our\\nformalism, leaving numerical simulations as the yardstick. We have evaluated numerically\\nthe large a approximation of our theory for Perceptron learning, 9[x, z] = sgn(z)O[-xz],\\nand for Adatron learning, 9[x, z] = sgn(z)lzIO[-xz]. This approximation leads to the\\nfollowing fully explicit equation for the field distributions:\\n\\n1/\\n\\nd\\n-p?[xly]\\n= dt\\na\\n.\\n\\nWith\\n\\nU=\\n\\n' +1\\n\\ndx' p?[x'ly]{o[x-x'-.,.,.1'[x', ?y]] -o[x-x]}\\n\\n_ ~ {P[ I ] [W _\\n.,., 8\\nx y\\ny\\n\\nJ\\n\\nX\\n\\n~ p?[xly]\\n\\n_.,.,2 Z!:I 2\\n2\\nuX\\n\\n,X + U[X?(y)-RY]+(V-RW)[X-X?(y)]]}\\nQ _ R2\\n\\nDydx {(I-A)P+[xly][x-P(y)]9[x,Y]+AP-[xly][x-x-(y)]9[x,-y])\\nV =\\nW=\\nZ=\\n\\n!\\n1\\n1\\n\\nDydx x {(I-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\nDydx y {(1-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\n\\nDydx {(I-A)P+[xly]92[x, Y]+AP-[xly]9 2[x,-yJ)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n243\\n\\nJ\\n\\nand with the short-hands X?(y) = dx xP?[xly). The result of our comparison is shown\\nin figure 2. Note: E t increases monotonically with a, and Eg decreases monotonically\\nwith a, at any t. As in the noise-free formalism [7], the large a approximation appears to\\ncapture the dominant terms both for a -7 00 and for a -7 O. The predicting power of our\\ntheory is mainly limited by numerical constraints. For instance, the Adatron learning rule\\ngenerates singularities at x = 0 in the distributions P?[xly) (especially for small \\\"I) which,\\nalthough predicted by our theory, are almost impossible to capture in numerical solutions.\\n\\n8 Discussion\\nWe have shown how a recent theory to describe the dynamics of supervised learning with\\nrestricted training sets (designed to apply in the data recycling regime, and for arbitrary online and batch learning rules) [5, 6, 7] in large layered neural networks can be generalized\\nsuccessfully in order to deal also with noisy teachers. In our generalized approach the joint\\ndistribution P[x, y, z) for the fields of student, 'clean' teacher, and noisy teacher is taken to\\nbe a dynamical order parameter, in addition to the conventional observables Q and R. From\\nthe order parameter set {Q, R, P} we derive the generalization error Eg and the training\\nerror E t . Following the prescriptions of dynamical replica theory one finds a diffusion\\nequation for P[x, y, z], which we have evaluated by making the replica-symmetric ansatz.\\nWe have carried out several orthogonal benchmark tests of our theory: (i) for a -7 00 (no\\ndata recycling) our theory is exact, (ii) for A -7 0 (no teacher noise) our theory reduces\\nto that of [5, 6, 7], and (iii) for batch Hebbian learning our theory is exact. For on-line\\nHebbian learning our theory is exact with regard to the predictions for Q, R, Eg and the\\ny-dependent conditional averages Jdx xP?[xly), at any time, and a crude approximation\\nof our equations already gives reasonable agreement with the exact results [9] for E t . For\\nnon-linear learning rules (Perceptron and Adatron) we have compared numerical solution\\nof a simple large a aproximation of our equations to numerical simulations, and found\\nsatisfactory agreement. This paper is a preliminary presentation of results obtained in the\\nsecond stage of a research programme aimed at extending our theoretical tools in the arena\\nof learning dynamics, building on [5, 6, 7]. Ongoing work is aimed at systematic application of our theory and its approximations to various types of non-linear learning rules, and\\nat generalization of the theory to multi-layer networks.\\n\\nReferences\\n[1]\\n[2]\\n[3]\\n[4]\\n[5]\\n[6]\\n[7]\\n[8]\\n[9]\\n[10]\\n[11]\\n[12]\\n\\nMace C.W.H. and Coolen AC.C (1998), Statistics and Computing 8, 55\\nSaad D. (ed.) (1998), On-Line Learning in Neural Networks (Cambridge: CUP)\\nHertz J.A., Krogh A and Thorgersson G.I. (1989), J. Phys. A 22, 2133\\nHomerH. (1992a), Z. Phys. B 86, 291 and Homer H. (1992b), Z. Phys. B 87,371\\nCoolen A.C.C. and Saad D. (1998), in On-Line Learning in Neural Networks, Saad\\nD. (ed.), (Cambridge: CUP)\\nCoolen AC.C. and Saad D. (1999), in Advances in Neural Information Processing\\nSystems 11, Kearns D., Solla S.A., Cohn D.A (eds.), (MIT press)\\nCoolen A.C.C. and Saad D. (1999), preprints KCL-MTH-99-32 & KCL-MTH-99-33\\nRae H.C., Sollich P. and Coolen AC.C. (1999), in Advances in Neural Information\\nProcessing Systems 11, Kearns D., Solla S.A., Cohn D.A. (eds.), (MIT press)\\nRae H.C., Sollich P. and Coolen AC.C. (1999),J. Phys. A 32, 3321\\nInoue J.I. (1999) private communication\\nWong K.YM., Li S. and Tong YW. (1999),preprint cond-mat19909004\\nBiehl M., Riegler P. and Stechert M. (1995), Phys. Rev. E 52, 4624\\n\\n\\f\",\n          \"Predicting Action Content On-Line and in\\nReal Time before Action Onset ? an\\nIntracranial Human Study\\n\\nShengxuan Ye\\nCalifornia Institute of Technology\\nPasadena, CA\\nsye@caltech.edu\\n\\nUri Maoz\\nCalifornia Institute of Technology\\nPasadena, CA\\nurim@caltech.edu\\nIan Ross\\nHuntington Hospital\\nPasadena, CA\\nianrossmd@aol.com\\n\\nAdam Mamelak\\nCedars-Sinai Medical Center\\nLos Angeles, CA\\nadam.mamelak@cshs.org\\n\\nChristof Koch\\nCalifornia Institute of Technology\\nPasadena, CA\\nAllen Institute for Brain Science\\nSeattle, WA\\nkoch@klab.caltech.edu\\n\\nAbstract\\nThe ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientific study of decision-making,\\nagency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious,\\nvoluntary action as well as for brain-machine interfaces. Here, epilepsy patients,\\nimplanted with intracranial depth microelectrodes or subdural grid electrodes for\\nclinical purposes, participated in a ?matching-pennies? game against an opponent.\\nIn each trial, subjects were given a 5 s countdown, after which they had to raise\\ntheir left or right hand immediately as the ?go? signal appeared on a computer\\nscreen. They won a fixed amount of money if they raised a different hand than\\ntheir opponent and lost that amount otherwise. The question we here studied was\\nthe extent to which neural precursors of the subjects? decisions can be detected in\\nintracranial local field potentials (LFP) prior to the onset of the action.\\nWe found that combined low-frequency (0.1?5 Hz) LFP signals from 10 electrodes\\nwere predictive of the intended left-/right-hand movements before the onset of the\\ngo signal. Our ORT system predicted which hand the patient would raise 0.5 s\\nbefore the go signal with 68?3% accuracy in two patients. Based on these results,\\nwe constructed an ORT system that tracked up to 30 electrodes simultaneously,\\nand tested it on retrospective data from 7 patients. On average, we could predict\\nthe correct hand choice in 83% of the trials, which rose to 92% if we let the system\\ndrop 3/10 of the trials on which it was less confident. Our system demonstrates?\\nfor the first time?the feasibility of accurately predicting a binary action on single\\ntrials in real time for patients with intracranial recordings, well before the action\\noccurs.\\n\\n1\\n\\n\\f1\\n\\nIntroduction\\n\\nThe work of Benjamin Libet [1, 2] and others [3, 4] has challenged our intuitive notions of the relation between decision making and conscious voluntary action. Using electrocorticography (EEG),\\nthese experiments measured brain potentials from subjects that were instructed to flex their wrist at a\\ntime of their choice and note the position of a rotating dot on a clock when they felt the urge to move.\\nThe results suggested that a slow cortical wave measured over motor areas?termed ?readiness potential? [5], and known to precede voluntary movement [6]?begins a few hundred milliseconds before the average reported time of the subjective ?urge? to move. This suggested that action onset and\\ncontents could be decoded from preparatory motor signals in the brain before the subject becomes\\naware of an intention to move and of the contents of the action. However, the readiness potential\\nwas computed by averaging over 40 or more trials aligned to movement onset after the fact. More\\nrecently, it was shown that action contents can be decoded using functional magnetic-resonance\\nimaging (fMRI) several seconds before movement onset [7]. But, while done on a single-trial basis,\\ndecoding the neural signals took place off-line, after the experiment was concluded, as the sluggish\\nnature of fMRI hemodynamic signals precluded real-time analysis. Moreover, the above studies\\nfocused on arbitrary and meaningless action?purposelessly raising the left or right hand?while\\nwe wanted to investigate prediction of reasoned action in more realistic, everyday situations with\\nconsequences for the subject.\\nIntracranial recordings are good candidates for single-trial, ORT analysis of action onset and contents [8, 9], because of the tight temporal pairing of LFP to the underlying neuronal signals. Moreover, such recordings are known to be cleaner and more robust, with signal-to-noise ratios up to\\n100 times larger than surface recordings like EEG [10, 11]. We therefore took advantage of a rare\\nopportunity to work with epilepsy patients implanted with intracranial electrodes for clinical purposes. Our ORT system (Fig. 1) predicts, with far above chance accuracy, which one of two future\\nactions is about to occur on this one trial and feeds the prediction back to the experimenter, all\\nbefore the onset of the go signal that triggers the patient?s movement (see Experimental Methods).\\nWe achieve relatively high prediction performance using only part of the data?learning from brain\\nactivity in past trials only (Fig. 2) to predict future ones (Fig. 3)?while still running the analysis\\nquickly enough to act upon the prediction before the subject moved.\\n\\n2\\n2.1\\n\\nExperimental Methods\\nSubjects\\n\\nSubjects in this experiment were 8 consenting intractable epilepsy patients that were implanted with\\nintracranial electrodes as part of their presurgical clinical evaluation (ages 18?60, 3 males). They\\nwere inpatients in the neuro-telemetry ward at the Cedars Sinai Medical Center or the Huntington\\nMemorial Hospital, and are designated with CS or HMH after their patient numbers, respectively. Six\\nof them?P12CS, P15CS, P22CS and P29?31HMH were implanted with intracortical depth electrodes targeting their bilateral anterior-cingulate cortex, amygdala, hippocampus and orbitofrontal\\ncortex. These electrodes had eight 40 ?m microwires at their tips, 7 for recording and 1 serving as\\na local ground. Two patients, P15CS and P22CS, had additional microwires in the supplementary\\nmotor area. We utilized the LFP recorded from the microwires in this study. Two other patients,\\nP16CS and P19CS, were implanted with an 8?8 subdural grid (64 electrodes) over parts of their\\ntemporal and prefrontal dorsolateral cortices. The data of one patient?P31HMH?was excluded\\nbecause microwire signals were too noisy for meaningful analysis. The institutional review boards\\nof Cedars Sinai Medical Center, the Huntington Memorial Hospital and the California Institute of\\nTechnology approved the experiments.\\nDuring the experiment, the subject sat in a hospital bed in a semi-inclined ?lounge chair? position.\\nThe stimulus/analysis computer (bottom left of Fig. 4) displaying the game screen (bottom right\\ninset of Fig. 4) was positioned to be easily viewable for the subject. When playing against the\\nexperimenter, the latter sat beside the bed. The response box was placed within easy reach of the\\nsubject (Fig. 4).\\n2\\n\\n\\f2.2\\n\\nExperiment Design\\n\\nAs part of our focus on purposeful, reasoned action, we had the subjects play a matching-pennies\\ngame?a 2-choice version of ?rock paper scissors??either against the experimenter or against a\\ncomputer. The subjects pressed down a button with their left hand and another with their right on a\\nresponse box. Then, in each trial, there was a 5 s countdown followed by a go signal, after which\\nthey had to immediately lift one of their hands. It was agreed beforehand that the patient would win\\nthe trial if she lifted a different hand than her opponent, and lose if she raised the same hand as her\\nopponent. Both players started off with a fixed amount of money, $5, and in each trial $0.10 was\\ndeducted from the loser and awarded to the winner. If a player lifted her hand before the go signal,\\ndid not lift her hand within 500 ms of the go signal, or lifted no hand or both hands at the go signal?\\nan error trial?she lost $0.10 without her opponent gaining any money. The subjects were shown the\\ncountdown, the go signal, the overall score, and various instructions on a stimulus computer placed\\nbefore them (Fig. 4). Each game consisted of 50 trials. If, at the end of the game, the subject had\\nmore money than her opponent, she received that money in cash from the experimenter.\\nBefore the experimental session began, the experimenter explained the rules of the game to the subject, and she could practice playing the game until she was familiar with it. Consequently, patients\\nusually made only few errors during the games (<6% of the trials). Following the tutorial, the subject played 1?3 games against the computer and then once against the experimenter, depending on\\ntheir availability and clinical circumstances. The first 2 games of P12CS were removed because\\nthe subject tended to constantly raise the right hand regardless of winning or losing. Two patients,\\nP15CS and P19CS, were tested in actual ORT conditions. In such sessions?3 games each?the\\nsubjects always played against the experimenter. These ORT games were different from the other\\ngames in two respects. First, a computer screen was placed behind the patient, in a location where\\nshe could not see it. Second, the experimenter was wearing earphones (Fig. 1,4). Half a second before go-signal onset, an arrow pointing towards the hand that the system predicted the experimenter\\nhad to raise to win the trial was displayed on that screen. Simultaneously, a monophonic tone was\\nplayed in the experimenter?s earphone ipsilateral to that hand. The experimenter then lifted that hand\\nat the go signal (see Supplemental Movie).\\n\\nCheetah Machine\\nCollect\\nand save\\ndata\\n\\nPatient\\nwith intracranial electrodes\\n\\nDown\\nsampling\\n\\nBuffer\\n\\n1Gbps\\nRouter\\n\\nTTL Signal\\n\\nThe winner is\\nPlayer 1\\nPLAYER 1 PLAYER 2\\nSCORE 1\\n\\nAnalysis/stimulus machine\\n\\nSCORE 2\\n\\nResponse Box Game Screen\\n\\n/\\nExperimenter\\n\\nResult\\nInterpreta\\ntion\\n\\nAnalysis\\n\\nFiltering\\n\\nDisplay/Sound\\n\\nFigure 1: A schematic diagram of the on-line real-time (ORT) system. Neural signals flow from\\nthe patient through the Cheetah machine to the analysis/stimulus computer, which controls the input\\nand output of the game and computes the prediction of the hand the patient would raise at the go\\nsignal. It displays it on a screen behind the patient and informs the experimenter which hand to raise\\nby playing a tone in his ipsilateral ear using earphones.\\n\\n3\\n\\n\\f3\\n3.1\\n\\nThe real-time system\\nHardware and software overview\\n\\n?V\\n\\n?V\\n\\n?V\\n\\nNeural data from the intracranial electrodes were transferred to a recording system (Neuralynx,\\nDigital Lynx), where it was collected and saved to the local Cheetah machine, down sampled\\nfrom 32 kHz to 2 kHz and buffered. The data were then transferred, through a dedicated 1 Gbps\\nlocal-area network, to the analysis/stimulus machine. This computer first band-pass-filtered the\\ndata to the 0.1?5 Hz range (delta and lower theta bands) using a second-order zero-lag elliptic\\nfilter with an attenuation of 40 dB (cf. Figs. 2a and 2b). We found that this frequency range?\\ngenerally comparable to that of the readiness potential?resulted in optimal prediction performance.\\nIt then ran the analysis algorithm (see below) on the filtered data. This computer also controlled\\nthe game screen, displaying the names of the players, their current scores and various instructions.\\nThe analysis/stimulus computer further\\ncontrolled the response box, which con- (a)\\n800\\nsisted of 4 LED-lit buttons. The buttons of the subject and her opponent\\n600\\nflashed red or blue whenever she or her\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nopponent won, respectively. Addition(b)100\\nally, the analysis/stimulus computer sent\\n0\\na unique transistor-transistor logic (TTL)\\n?100\\n?200\\npulse whenever the game screen changed\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nor a button was pressed on the response\\nbox, which synchronized the timing of (c) 100\\n0\\nthese events with the LFP recordings.\\n?100\\nIn real-time game sessions, the analy?200\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nsis/stimulus computer also displayed the\\nappropriate arrow on the computer screen (d) 1\\nbehind the subject and played the tone\\n0\\nto the appropriate ear of the experimenter\\n?1\\n0.5 s before go-signal onset (Figs. 1,4).\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nThe analysis software was based on a\\nmachine-learning algorithm that trained\\non past-trials data to predict the current\\ntrial and is detailed below. The training phase included the first 70% of the\\ntrials, with the prediction carried out on\\nthe remaining 30% using the trained parameters, together with an online weighting system (see below). The system examined only neural activity, and had no\\naccess to the subject?s left/right-choice\\nhistory. After filtering all the training\\ntrials (Fig. 2b), the system found the\\nmean and standard error over all leftward\\nand rightward training trials, separately\\n(Fig. 2c, left designated in red). It then\\nfound the electrodes and time windows\\nwhere the left/right separation was high\\n(Fig. 2d,e; see below), and trained the classifiers on these time windows (Fig. 2f?g).\\nThe best electrode/time-window/classifier\\n(ETC) combinations were then used to\\npredict the current trial in the prediction\\nphase (Fig. 3). The number of ETCs that\\ncan be actively monitored is currently limited to 10 due to the computational power\\nof the real-time system.\\n\\nEl 49?T1\\n\\n(e)\\n\\nEl 49?T2\\n\\nEl 49?T3\\n\\n1\\n0\\n?1\\n?5\\n\\n?4\\n\\n?3\\n?2\\n?1\\nCountdown to go signal at t=0 (seconds)\\n\\n0\\n\\n(f)\\nClassifier\\nCf1\\n\\nClassifier\\nCf2\\n\\n...\\n\\nClassifier\\nCf6\\n\\nEl 49?T1?Cf1\\nEl 49?T1?Cf2\\nEl 49?T1?Cf6\\n...\\nEl 49?T2?Cf1\\nEl 49?T2?Cf2\\nEl 49?T2?Cf6\\nEl 49?T3?Cf1\\nEl 49?T3?Cf2\\nEl 49?T3?Cf6\\n\\n(g)\\nCombination\\nEl49-T1-Cf2\\n\\nCombination\\nEl49-T2-Cf2\\n\\n...\\n\\nCombination\\nEl49-T2-Cf6\\n\\nFigure 2: The ORT-system?s training phase. Left (in\\nred) and right (in blue) raw signals (a) are low-pass filtered (b). Mean?standard errors of signals preceeding left- and right-hand movments (c) are used to compute a left/right separability index (d), from which time\\nwindows with good separation are found (e). Seven\\nclassifiers are then applied to all the time windows (f)\\nand the best electrode/time-window/classifier combinations are selected (g) and used in the prediction phase\\n(Fig. 3).\\n\\n4\\n\\n\\f?V\\n\\n100\\n0\\n?100\\n?200\\n?5\\n\\n?4\\n\\n?3\\n\\n?2\\n\\n?1\\n\\n0\\n\\nTrained classifiers\\n\\nCombination\\nE l 49?T1?Cf2\\n\\nCombination\\nE l 49?T2?Cf2\\n\\nWeight = 1\\n\\nWeight = 1\\n\\nCombination\\nE l 49?T2?Cf6\\n\\n&\\n\\nWeight = 1\\n\\nPredicted result\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nR\\n\\nL\\n\\n&\\n\\nR\\n\\nL\\nReal result\\n\\nAdjust the weights\\n\\nL\\n\\n==\\n\\nFigure 3: The ORT-system?s prediction phase. A new signal?from 5 to 0.5 seconds before the\\ngo signal?is received in real time, and each electrode/time-window/classifier combination (ETC)\\nclassifies it as resulting in left- or right-hand movement. These predictions are then compared to the\\nactual hand movement, with the weights associated with ETCs that correctly (incorrectly) predicted\\nincreasing (decreasing).\\n\\n3.2\\n\\nComputing optimal left/right-separating time windows\\n\\nThe algorithm focused on finding the time windows with the best left/right separation for the different recording electrodes over the training set (Fig. 2c?e). That is, we wanted to predict whether\\nthe signal aN (t) on trial N will result in a leftward or rightward movement?i.e., whether the label of the N th trial will be Lt or Rt, respectively. For each electrode, we looked at the N ? 1\\nprevious trials a1 (t), a2 (t), . . . , aN ?1 (t), and their associated labels as l1 , l2 , . . . , lN ?1 . Now, let\\nN ?1\\n?1\\nL(t) = {ai (t) | li = Lt}N\\ni=1 and R(t) = {ai (t) | li = Rt}i=1 be the set of previous leftward and\\nrightward trials in the training set, respectively. Furthermore, let Lm (t) (Rm (t)) and Ls (t) (Rs (t))\\nbe the mean and standard error of L(t) (R(t)), respectively. We can now define the normalized\\nrelative left/right separation for each electrode at time t (see Fig. 2d):\\n?\\n[Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)]\\n?\\n?\\nif [Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)] > 0\\n?\\n?\\nLm (t) ? Rm (t)\\n?\\n?\\n?\\n?\\n?\\n[Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)]\\n?(t) =\\n?\\nif [Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)] > 0\\n?\\n?\\n?\\nRm (t) ? Lm (t)\\n?\\n?\\n?\\n?\\n?\\n?\\n0\\notherwise\\nThus, ?(t) > 0 (?(t) < 0) means that the leftward trials tend to be considerably higher (lower)\\nthan rightward trials for that electrode at time t, while ?(t) = 0 suggests no left/right separation at\\ntime t. We define a consecutive time period of |?(t)| > 0 for t < prediction time (the time before\\nthe go signal when we want the system to output a prediction; -0.5 s for the ORT trials) as a time\\nwindow (Fig. 2e). After all time windows are found for all electrodes, time windows lessRthan M ms\\nt\\napart are combined into one. Then, for each time window from t1 to t2 we define a = t12 |?(t)|dt.\\nWe then eliminate all time windows satisfying a < A. We found the values M = 200 ms and\\nA = 4, 500 ?V ? ms to be optimal for real-time analysis. This resulted in 20?30 time windows over\\nall 64 electrodes that we monitored.\\n5\\n\\n\\f1\\n$4.80\\n\\n$5.20\\n\\nP15CS\\n\\nUri\\n\\nFigure 4: The experimental setup in the clinic. At 400 ms before the go signal, the patient and\\nexperimenter are watching the game screen (inset on bottom right) on the analysis/stimulus computer\\n(bottom left) and still pressing down the buttons of the response box. The realtime system already\\ncomputed a prediction, and thus displays an arrow on the screen behind the patient and plays a tone\\nin the experimenter?s ear ipsilateral to the hand it predicts he should raise to beat the patient (see\\nSupplemental Movie).\\n3.3\\n\\nClassifiers selection and ETC determination\\n\\nWe used ensemble learning with 7 types of relatively simple binary classifiers (due to real-time\\nprocessing considerations) on every electrode?s time windows (Fig. 2f). Classifiers A to G would\\nclassify aN (t) as Lt if:\\nP\\nP\\nP\\n(A) Defining aN,M , Lm,M and Rm,M as aN (t), Lm (t) and Rm (t) over time window M ,\\n\\u0001\\n\\u0001\\n\\u0001\\n(i) sign Rm,M 6= sign aN,M = sign Lm,M , or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(ii) sign Rm,M = sign aN,M = sign Lm,M and \\fLm,M \\f > \\fRm,M \\f, or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(iii) sign Rm (t) 6= sign SN,M 6= sign Lm (t) and \\fLm,M \\f < \\fRm,M \\f;\\n\\f\\n\\u0001\\n\\u0001\\f \\f\\n\\u0001\\n\\u0001\\f\\n(B) \\fmean aN (t) ? mean Lm (t) \\f < \\fmean aN (t) ? mean Rm (t) \\f;\\n\\f\\n\\f\\n\\u0001\\n\\u0001\\f\\n\\u0001\\n\\u0001\\f\\n(C) \\fmedian aN (t) ? median Lm (t) \\f < \\fmedian aN (t) ? median Rm (t) \\f over the time\\nwindow;\\n\\f\\n\\f\\n\\f\\n\\f\\n\\f\\n(D) aN (t) ? Lm (t)\\fL2 < \\faN (t) ? Rm (t)\\fL2 over the time window;\\n(E) aN (t) is convex/concave like Lm (t) while Rm (t) is concave/convex, respectively;\\n(F) Linear support-vector machine (SVM) designates it as so; and\\n(G) k-nearest neighbors (KNN) with Euclidean distance designates it as so.\\nEach classifier is optimized for certain types of features. To estimate how well its classification\\nwould generalize from the training to the test set, we trained and tested it using a 70/30 crossvalidation procedure within the training set. We tested each classifier on every time window of every\\nelectrode, discarding those with accuracy <0.68, which left 12.0 ? 1.6% of the original 232 ? 18\\nETCs, on average (?standard error). The training phase therefore ultimately output a set of S binary\\nETC combinations (Fig. 2g) that were used in the prediction phase (Fig. 3).\\n3.4\\n\\nThe prediction-phase weighting system\\n\\nIn the prediction phase, each of the overall S binary ETCs calculates a prediction, ci ? {?1, 1} (for\\nright and left, respectively), independently at the desired prediction time. All classifiers are initially\\n6\\n\\n\\fPS\\ngiven the same weight, w1 = w2 = ? ? ? = wS = 1. We then calculate ? = i=1 wi ? ci and predict\\nleft (right) if ? > d (? < ?d), or declare it an undetermined trial if ?d < ? < d. Here d is the\\ndrop-off threshold for the prediction. Thus the larger d is, the more confident the system needs to be\\nto make a prediction, and the larger the proportion of trials on which the system abstains?the dropoff rate. Weight wi associated with ETCi is increased (decreased) by 0.1 whenever ETCi predicts\\nthe hand movement correctly (incorrectly). A constantly erring ETC would therefore be associated\\nwith an increasingly small and then increasingly negative weight.\\n3.5\\n\\nImplementation\\n\\nThe algorithm was implemented in MATLAB 2011a (MathWorks, Natick, MA) as well as in C++\\non Visual Studio 2008 (Microsoft, Redmond, WA) for enhanced performance. The neural signals\\nwere collected by the Digital Lynx S system using Cheetah 5.4.0 (Neuralynx, Redmond, WA). The\\nsimulated-ORT system was also implemented in MATLAB 2011a. The simulated-ORT analyses\\ncarried out in this paper used real patient data saved on the Digital Lynx system.\\n1\\n\\n0.9\\n\\nDrop rate:\\nNone\\n0.18\\n0\\u0011\\u0016\\u0013\\n\\nPrediction accuracy\\n\\n0.8\\n\\n0.7\\nSignificant accuracy\\n(p=0.05)\\n0.6\\n\\n0.5\\n\\n?5\\n\\n?4.5\\n\\n?4\\n\\n?3.5\\n\\n?3\\n\\n?2.5\\nTime (s)\\n\\n?2\\n\\n?1.5\\n\\n?1\\n\\n?0.5\\n\\n0\\nGo-signal\\nonset\\n\\nFigure 5: Across-subjects average of the prediction accuracy of simulated-ORT versus time before\\nthe go signal. The mean accuracies over time when the system predicts on every trial, is allowed\\nto drop 19% or 30% of the trials, are depicted in blue, green and red, respectively (?standard error\\nshaded). Values above the dashed horizontal line are significant at p = 0.05.\\n\\n4\\n\\nResults\\n\\nWe tested our prediction system in actual real time on 2 patients?P15CS and P19CS (a depth\\nand grid patient, respectively), with a prediction time of 0.5 s before the go signal (see Supplementary Movie). Because of computational limitations, the ORT system could only track 10\\nelectrodes with just 1 ETC per electrode in real time. For P15CS, we achieved an accuracy of\\n72?2% (?standard error; accuracy = number of accurately predicted trials / [total number of trials - number of dropped trials]; p = 10?8 , binomial test) without modifying the weights online during the prediction (see Section 3.4). For P19CS we did not run patient-specific training of the ORT system, and used parameter values that were good on average over previous patients instead. The prediction accuracy was significantly above chance 63?2% (?standard error; p = 7 ? 10?4 , binomial test). To understand how much we could improve our accuracy\\nwith optimized hardware/software, we ran the simulated-ORT at various prediction times along\\n7\\n\\n\\fAccuracy\\n\\nthe 5 s countdown leading to the go signal. We further tested 3 drop-off rates?0, 0.19 and\\n0.30 (Fig. 5; drop-off rate = number of dropped trials / total number of trials; these resulted\\nfrom 3 drop-off thresholds?0, 0.1 and 0.2?respectively, see Section 3.4:). Running offline,\\nwe were able to track 20?30 ETCs, which resulted in considerably higher accuracies (Figs. 5,6).\\nAveraged over all subjects, the accuracy rose from about 65% more than\\n1\\n4 s before the go signal to 83?92%\\nclose to go-signal onset, depending\\n0.9\\non the allowed drop-off rate. In particular, we found that for a predic0.8\\ntion time of 0.5 s before go-signal\\nonset, we could achieve accuracies\\n0.7\\nof 81?5% and 90?3% (?standard\\nerror) for P15CS and P19CS, re0.6\\nspectively, with no drop off (Fig. 6).\\nPatients:\\nP12CS\\nWe also analyzed the weights that\\nP15CS\\nour weighting system assigned to the\\n0.5\\nP16CS\\nP19CS\\ndifferent ETCs. We found that the\\nP22CS\\nempirical distribution of weights to\\nP29HMH\\n0.4\\nP30HMH\\nETCs associated with classifiers A to\\nG was, on average: 0.15, 0.12, 0.16,\\n?5 ?4.5 ?4 ?3.5 ?3 ?2.5 ?2 ?1.5 ?1 ?0.5 0\\n0.22, 0.01, 0.26 and 0.07, respecTime before go signal (at t=0) (seconds)\\ntively. This suggests that the linear\\nSVM and L2-norm comparisons (of\\naN to Lm and Rm ) together make up Figure 6: Simulated-ORT accuracy over time for individual\\nnearly half of the overall weights at- patients with no drop off.\\ntributed to the classifiers, while the\\ncurrent concave/convex measure is of\\nlittle use as a classifier.\\n\\n5\\n\\nDiscussion\\n\\nWe constructed an ORT system that, based on intracranial recordings, predicted which hand a person would raise well before movement onset at accuracies much greater than chance in a competitive environment. We further tested this system off-line, which suggested that with optimized\\nhardware/software, such action contents would be predictable in real time at relatively high accuracies already several seconds before movement onset. Both our prediction accuracy and drop-off\\nrates close to movement onset are superior to those achieved before movement onset with noninvasive methods like EEG and fMRI [7, 12?14]. Importantly, our subjects played a matching pennies game?a 2-choice version of rock-paper-scissors [15]?to keep their task realistic, with minor\\nthough real consequences, unlike the Libet-type paradigms whose outcome bears no consequences\\nfor the subjects. It was suggested that accurate online, real-time prediction before movement onset\\nis key to investigating the relation between the neural correlates of decisions, their awareness, and\\nvoluntary action [16, 17]. Such prediction capabilities would facilitate many types of experiments\\nthat are currently infeasible. For example, it would make it possible to study decision reversals on\\na single-trial basis, or to test whether subjects can guess above chance which of their action contents are predictable from their current brain activity, potentially before having consciously made up\\ntheir mind [16, 18]. Accurately decoding these preparatory motor signals may also result in earlier\\nand improved classification for brain-computer interfaces [13, 19, 20]. The work we present here\\nsuggests that such ORT analysis might well be possible.\\nAcknowledgements\\nWe thank Ueli Rutishauser, Regan Blythe Towel, Liad Mudrik and Ralph Adolphs for meaningful\\ndiscussions. This research was supported by the Ralph Schlaeger Charitable Foundation, Florida\\nState University?s ?Big Questions in Free Will? initiative and the G. Harold & Leila Y. Mathers\\nCharitable Foundation.\\n8\\n\\n\\fReferences\\n[1] B. Libet, C. Gleason, E. Wright, and D. Pearl. Time of conscious intention to act in relation to\\nonset of cerebral activity (readiness-potential): The unconscious initiation of a freely voluntary\\nact. Brain, 106:623, 1983.\\n[2] B. Libet. Unconscious cerebral initiative and the role of conscious will in voluntary action.\\nBehavioral and brain sciences, 8:529?539, 1985.\\n[3] P. Haggard and M. Eimer. On the relation between brain potentials and the awareness of\\nvoluntary movements. Experimental Brain Research, 126:128?133, 1999.\\n[4] A. Sirigu, E. Daprati, S. Ciancia, P. Giraux, N. Nighoghossian, A. Posada, and P. Haggard.\\nAltered awareness of voluntary action after damage to the parietal cortex. Nature Neuroscience,\\n7:80?84, 2003.\\n[5] H. Kornhuber and L. Deecke. Hirnpotenti?alanderungen bei Willk?urbewegungen und passiven\\nBewegungen des Menschen: Bereitschaftspotential und reafferente Potentiale. Pfl?ugers Archiv\\nEuropean Journal of Physiology, 284:1?17, 1965.\\n[6] H. Shibasaki and M. Hallett. What is the Bereitschaftspotential? Clinical Neurophysiology,\\n117:2341?2356, 2006.\\n[7] C. Soon, M. Brass, H. Heinze, and J. Haynes. Unconscious determinants of free decisions in\\nthe human brain. Nature Neuroscience, 11:543?545, 2008.\\n[8] I. Fried, R. Mukamel, and G. Kreiman. Internally generated preactivation of single neurons in\\nhuman medial frontal cortex predicts volition. Neuron, 69:548?562, 2011.\\n[9] M. Cerf, N. Thiruvengadam, F. Mormann, A. Kraskov, R. Quian Quiorga, C. Koch, and\\nI. Fried. On-line, voluntary control of human temporal lobe neurons. Nature, 467:1104?1108,\\n2010.\\n[10] T. Ball, M. Kern, I. Mutschler, A. Aertsen, and A. Schulze-Bonhage. Signal quality of simultaneously recorded invasive and non-invasive EEG. Neuroimage, 46:708?716, 2009.\\n[11] G. Schalk, J. Kubanek, K. Miller, N. Anderson, E. Leuthardt, J. Ojemann, D. Limbrick,\\nD. Moran, L. Gerhardt, and J. Wolpaw. Decoding two-dimensional movement trajectories\\nusing electrocorticographic signals in humans. Journal of Neural engineering, 4:264, 2007.\\n[12] O. Bai, V. Rathi, P. Lin, D. Huang, H. Battapady, D. Y. Fei, L. Schneider, E. Houdayer, X. Chen,\\nand M. Hallett. Prediction of human voluntary movement before it occurs. Clinical Neurophysiology, 122:364?372, 2011.\\n[13] O. Bai, P. Lin, S. Vorbach, J. Li, S. Furlani, and M. Hallett. Exploration of computational\\nmethods for classification of movement intention during human voluntary movement from\\nsingle trial EEG. Clinical Neurophysiology, 118:2637?2655, 2007.\\n[14] U. Maoz, A. Arieli, S. Ullman, and C. Koch. Using single-trial EEG data to predict laterality\\nof voluntary motor decisions. Society for Neuroscience, 38:289.6, 2008.\\n[15] C. Camerer. Behavioral game theory: Experiments in strategic interaction. Princeton University Press, 2003.\\n[16] J. D. Haynes. Decoding and predicting intentions. Annals of the New York Academy of Sciences, 1224:9?21, 2011.\\n[17] P. Haggard. Decision time for free will. Neuron, 69:404?406, 2011.\\n[18] J. D. Haynes. Beyond libet. In W. Sinnott-Armstrong and L. Nadel, editors, Conscious will\\nand responsibility, pages 85?96. Oxford University Press, 2011.\\n[19] A. Muralidharan, J. Chae, and D. M. Taylor. Extracting attempted hand movements from EEGs\\nin people with complete hand paralysis following stroke. Frontiers in neuroscience, 5, 2011.\\n[20] E. Lew, R. Chavarriaga, S. Silvoni, and J. R. Milln. Detection of self-paced reaching movement\\nintention from EEG signals. Frontiers in Neuroengineering, 5:13, 2012.\\n\\n9\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "papers"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-207fad8d-500b-4239-88f1-3667f539890e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207fad8d-500b-4239-88f1-3667f539890e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-207fad8d-500b-4239-88f1-3667f539890e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-207fad8d-500b-4239-88f1-3667f539890e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7bb7c10c-633a-4efd-a224-3e9e3ab1ed62\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bb7c10c-633a-4efd-a224-3e9e3ab1ed62')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7bb7c10c-633a-4efd-a224-3e9e3ab1ed62 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(\"NIPS Papers.zip\", \"r\") as zip_ref:\n",
        "    # Extract the file to a temporary directory\n",
        "    zip_ref.extractall(\"temp\")\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "papers = pd.read_csv(\"papers.csv\")\n",
        "\n",
        "# Print head\n",
        "papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP8TrGfm2SDW"
      },
      "source": [
        "** **\n",
        "#### Step 2: Data Cleaning\n",
        "** **\n",
        "\n",
        "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note: dropped all the columns except paper_text to foucs on it"
      ],
      "metadata": {
        "id": "e4U-CfG3M0Zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xf22DjRk2SDW",
        "outputId": "a716ff6d-53ff-47cf-bab2-f1eeb79e8ae5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Scaled Gradients on Grassmann Manifolds\\nfor Matrix Completion\\n\\nThanh T. Ngo and Yousef Saad\\nDepartment of Computer Science and Engineering\\nUniversity of Minnesota, Twin Cities\\nMinneapolis, MN 55455\\nthango@cs.umn.edu, saad@cs.umn.edu\\n\\nAbstract\\nThis paper describes gradient methods based on a scaled metric on the Grassmann\\nmanifold for low-rank matrix completion. The proposed methods significantly\\nimprove canonical gradient methods, especially on ill-conditioned matrices, while\\nmaintaining established global convegence and exact recovery guarantees. A connection between a form of subspace iteration for matrix completion and the scaled\\ngradient descent procedure is also established. The proposed conjugate gradient\\nmethod based on the scaled gradient outperforms several existing algorithms for\\nmatrix completion and is competitive with recently proposed methods.\\n\\n1\\n\\nIntroduction\\n\\nLet A ? Rm?n be a rank-r matrix, where r ? m, n. The matrix completion problem is to reconstruct A given a subset of entries of A. This problem has attracted much attention recently\\n[8, 14, 13, 18, 21] because of its broad applications, e.g., in recommender systems, structure from\\nmotion, and multitask learning (see e.g. [19, 9, 2]).\\n1.1\\n\\nRelated work\\n\\nLet ? = {(i, j)|Aij is observed}. We define P? (A) ? Rm?n to be the projection of A onto the\\nobserved entries ?: P? (A)ij = Aij if (i, j) ? ? and P? (A)ij = 0 otherwise. If the rank is\\nunknown and there is no noise, the problem can be formulated as:\\nMinimize rank (X) subject to P? (X) = P? (A).\\n\\n(1)\\n\\nRank minimization is NP-hard and so work has been done to solve a convex relaxation of it by\\napproximating the rank by the nuclear norm. Under some conditions, the solution of the relaxed\\nproblem can be shown to be the exact solution of the rank minimization problem with overwhelming\\nprobability [8, 18]. Usually, algorithms to minimize the nuclear norm iteratively use the Singular\\nValue Decomposition (SVD), specifically the singular value thresholding operator [7, 15, 17], which\\nmakes them expensive.\\nIf the rank is known, we can formulate the matrix completion problem as follows:\\nFind matrix X to minimize ||P? (X) ? P? (A)||F subject to rank (X) = r.\\n\\n(2)\\n\\nKeshavan et al. [14] have proved that exact recovery can be obtained with high probability by solving a non-convex optimization problem. A number of algorithms based on non-convex formulation\\nuse the framework of optimization on matrix manifolds [14, 22, 6]. Keshavan et al. [14] propose\\na steepest descent procedure on the product of Grassmann manifolds of r-dimensional subspaces.\\nVandereycken [22] discusses a conjugate gradient algorithm on the Riemann manifold of rank-r matrices. Boumal and Absil [6] consider a trust region method on the Grassmann manifold. Although\\n1\\n\\n\\fthey do not solve an optimization problem on the matrix manifold, Wei et al. [23] perform a low rank\\nmatrix factorization based on a successive over-relaxation iteration. Also, Srebro and Jaakkola [21]\\ndiscuss SVD-EM, one of the early fixed-rank methods using truncated singular value decomposition\\niteratively. Dai et al. [10] recently propose an interesting approach that does not use the Frobenius\\nnorm of the residual as the objective function but instead uses the consistency between the current\\nestimate of the column space (or row space) and the observed entries. Guaranteed performance for\\nthis method has been established for rank-1 matrices.\\nIn this paper, we will focus on the case when the rank r is known and solve problem (2). In fact,\\neven when the rank is unknown, the sparse matrix which consists of observed entries can give us a\\nvery good approximation of the rank based on its singular spectrum [14]. Also, a few values of the\\nrank can be used and the best one is selected. Moreover, the singular spectrum is revealed during\\nthe iterations, so many fixed rank methods can also be adapted to find the rank of the matrix.\\n1.2\\n\\nOur contribution\\n\\nOptSpace [14] is an efficient algorithm for low-rank matrix completion with global convergence and\\nexact recovery guarantees. We propose using a non-canonical metric on the Grassmann manifold to\\nimprove OptSpace while maintaining its appealing properties. The non-canonical metric introduces\\na scaling factor to the gradient of the objective function which can be interpreted as an adaptive\\npreconditioner for the matrix completion problem. The gradient descent procedure using the scaled\\ngradient is related to a form of subspace iteration for matrix completion. Each iteration of the\\nsubspace iteration is inexpensive and the procedure converges very rapidly. The connection between\\nthe two methods leads to some improvements and to efficient implementations for both of them.\\nThroughout the paper, A? will be a shorthand for P? (A) and qf(U ) is the Q factor in the QR\\nfactorization of U which gives an orthonormal basis for span (U ). Also, P?? (.) denotes the projection\\nonto the negation of ?.\\n\\n2\\n\\nSubspace iteration for incomplete matrices\\n\\nWe begin with a form of subspace iteration for matrix completion depicted in Algorithm 1. If the\\nAlgorithm 1 S UBSPACE I TERATION FOR INCOMPLETE MATRICES .\\nInput: Matrix A? , ?, and the rank r.\\nOutput: Left and right dominant subspaces U and V and associated singular values.\\n1: [U0 , ?0 , V0 ] = svd(A? , r), S0 = ?0 ;\\n// Initialize U , V and ?\\n2: for i = 0,1,2,... do\\n3:\\nXi+1 = P?? (Ui Si ViT ) + A?\\n// Obtain new estimate of A\\nT\\n4:\\nUi+1 = Xi+1 Vi ; Vi+1 = Xi+1\\nUi+1\\n// Update subspaces\\n5:\\nUi+1 = qf(Ui+1 ); Vi+1 = qf(Vi+1 )\\n// Re-orthogonalize bases\\nT\\n6:\\nSi+1 = Ui+1\\nXi+1 Vi+1\\n// Compute new S for next estimate of A\\n7:\\nif condition then\\n8:\\n// Diagonalize S to obtain current estimate of singular vectors and values\\n9:\\n[RU , ?i+1 , RV ] = svd(Si+1 ); Ui+1 = Ui+1 RU ; Vi+1 = Vi+1 RV ; Si+1 = ?i+1 .\\n10:\\nend if\\n11: end for\\nmatrix A is fully observed, U and V can be randomly initialized, line 3 is not needed and in lines\\n4 and 6 we use A instead of Xi+1 to update the subspaces. In this case, we have the classical twosided subspace iteration for singular value decomposition. Lines 6-9 correspond to a Rayleigh-Ritz\\nprojection to obtain current approximations of singular vectors and singular values. It is known that\\nif the initial columns of U and V are not orthogonal to any of the first r left and right singular vectors\\nof A respectively, the algorithm converges to the dominant subspaces of A [20, Theorem 5.1].\\nBack to the case when the matrix A is not fully observed, the basic idea of Algorithm 1 is to use\\nan approximation of A in each iteration to update the subspaces U and V and then from the new U\\nand V , we can obtain a better approximation of A for the next iteration. Line 3 is to compute a new\\nestimate of A by replacing all entries of Ui Si ViT at the known positions by the true values in A.\\nThe update in line 6 is to get the new Si+1 based on recently computed subspaces. Diagonalizing\\n2\\n\\n\\fSi+1 (lines 7-10) is optional for matrix completion. This step provides current approximations\\nof the singular values which could be useful for several purposes such as in regularization or for\\nconvergence test. This comes with very little additional overhead, since Si+1 is a small r ? r matrix.\\nEach iteration of Algorithm 1 can be seen as an approximation of an iteration of SVD-EM where a\\nfew matrix multiplications are used to update U and V instead of using a truncated SVD to compute\\nthe dominant subspaces of Xi+1 . Recall that computing an SVD, e.g. by a Lanczos type procedure,\\nrequires several, possibly a large number of, matrix multiplications of this type.\\nWe now discuss efficient implementations of Algorithm 1 and modifications to speed-up its conver? i = Ui Si V T . Then\\ngence. First, the explicit computation of Xi+1 in line 3 is not needed. Let X\\ni\\n? i + Ei , where Ei = P? (A ? X\\n? i ) is a sparse matrix of errors at\\nXi+1 = P?? (Ui Si ViT ) + A? = X\\n? i . Assume that each\\nknown entries which can be computed efficiently by exploiting the structure of X\\nSi is not singular (the non-singularity of Si will be discussed in Section 4). Then if we post-multiply\\nthe update of U in line 4 by Si?1 , the subspace remains the same, and the update becomes:\\n? i + Ei )Vi S ?1 = Ui + Ei Vi S ?1 ,\\nUi+1 = Xi+1 Vi Si?1 = (X\\ni\\ni\\n\\n(3)\\n\\nThe update of V can also be efficiently implemented. Here, we make a slight change, namely\\nT\\nVi+1 = Xi+1\\nUi (Ui instead of Ui+1 ). We observe that the convergence speed remains roughly the\\nsame (when A is fully observed, the algorithm is a slower version of subspace iteration where the\\nconvergence rate is halved). With this change, we can derive an update to V that is similar to (3),\\nVi+1 = Vi + EiT Ui Si?T ,\\n\\n(4)\\n\\nWe will point out in Section 3 that the updating terms Ei Vi Si?1 and EiT Ui Si?T are related to the\\ngradients of a matrix completion objective function on the Grassmann manifold. As a result, to\\nimprove the convergence speed, we can add an adaptive step size ti to the process, as follows:\\nUi+1 = Ui + ti Ei Vi Si?1\\n\\nand\\n\\nVi+1 = Vi + ti EiT Ui Si?T .\\n\\n? i + ti Ei as the estimate of A in each iteration. The step size can be\\nThis is equivalent to using X\\ncomputed using a heuristic adapted from [23]. Initially, t is set to some initial value t0 (t0 = 1 in\\nour experiments). If the error kEi kF decreases compared to the previous step, t is increased by a\\nfactor ?. Conversely, if the error increases, indicating that the step is too big, t is reset to t = t0 .\\nThe matrix Si+1 can be computed efficiently by exploiting low-rank structures and the sparsity.\\nT\\nT\\nSi+1 = (Ui+1\\nUi )Si (ViT Vi+1 ) + ti Ui+1\\nEi Vi+1\\n\\n(5)\\n\\nThere are also other ways to obtain Si+1 once Ui+1 and Vi+1 are determined to improve the current\\napproximation of A . For example we can solve the following quadratic program [14]:\\nT\\nSi+1 = argminS kP? (A ? Ui+1 SVi+1\\n)k2F\\n\\n(6)\\n\\nWe summarize the discussion in Algorithm 2. A sufficiently small error kEi kF can be used as a\\nAlgorithm 2 G ENERIC S UBSPACE I TERATION FOR INCOMPLETE MATRICES .\\nInput: Matrix A? , ?, and number r.\\nOutput: Left and right dominant subspaces U and V and associated singular values.\\n1: Initialize orthonormal matrices U0 ? Rm?r and V0 ? Rn?r .\\n2: for i = 0,1,2,... do\\n3:\\nCompute Ei and appropriate step size ti\\n4:\\nUi+1 = Ui + ti Ei Vi Si?1 and Vi+1 = Vi + ti EiT Ui Si?T\\n5:\\nOrthonormalize Ui+1 and Vi+1\\nT\\n6:\\nFind Si+1 such that P? (Ui+1 Si+1 Vi+1\\n) is close to A? (e.g. via (5), (6)).\\n7: end for\\nstoppping criterion. Algorithm 1 can be shown to be equivalent to LMaFit algorithm proposed in\\n[23]. The authors in [23] also obtain results on local convergence of LMaFit. We will pursue a\\ndifferent approach here. The updates (3) and (4) are reminiscent of the gradient descent steps for\\nminimizing matrix completion error on the Grassmann manifold that is introduced in [14] and the\\nnext section discusses the connection to optimization on the Grassmann manifold.\\n3\\n\\n\\f3\\n\\nOptimization on the Grassmann manifold\\n\\nIn this section, we show that using a non-canonical Riemann metric on the Grassmann manifold,\\nthe gradient of the same objective function in [14] is of a form similar to (3) and (4). Based on this,\\nimprovements to the gradient descent algorithms can be made and exact recovery results similar\\nto those of [14] can be maintained. The readers are referred to [1, 11] for details on optimization\\nframeworks on matrix manifolds.\\n3.1\\n\\nGradients on the Grassmann manifold for matrix completion problem\\n\\nLet G(m, r) be the Grassmann manifold in which each point corresponds to a subspace of dimension\\nr in Rm . One of the results of [14], is that under a few assumptions (to be addressed in Section 4),\\none can obtain with high probability the exact matrix A by minimizing a regularized version of the\\nfunction F : G(m, r) ? G(n, r) ? R defined below.\\nF (U, V ) = min\\nF(U, S, V ),\\nr?r\\n\\n(7)\\n\\nS?R\\n\\nwhere F(U, S, V ) = (1/2)kP? (A ? U SV T )k2F , U ? Rm?k and V ? Rn?k are orthonormal\\nmatrices. Here, we abuse the notation by denoting by U and V both orthonormal matrices as well\\nas the points on the Grassmann manifold which they span. Note that F only depends on the subspaces spanned by matrices U and V . The function F (U, V ) can be easily evaluated by solving\\nthe quadratic minimization problem in the form of (6). If G(m, r) is endowed with the canonical\\ninner product hW, W ? i = Tr (W T W ? ), where W and W ? are tangent vectors of G(m, r) at U (i.e.\\nW, W ? ? Rm?r such that W T U = 0 and W ?T U = 0) and similarly for G(n, r), the gradients of\\nF (U, V ) on the product manifold are:\\ngradFU (U, V )\\ngradFV (U, V )\\n\\n=\\n=\\n\\n(I ? U U T )P? (U SV T ? A)V S T\\nT\\n\\n(I ? V V )P? (U SV\\n\\nT\\n\\nT\\n\\n(8)\\n\\nT\\n\\n? A) U S.\\n\\n(9)\\n\\nT\\n\\nT\\n\\nIn the above formulas, (I ?U U ) and (I ?V V ) are the projections of the derivatives P? (U SV ?\\nA)V S T and P? (U SV T ? A)T U S onto the tangent space of the manifold at (U, V ). Notice that the\\nderivative terms are very similar to the updates in (3) and (4). The difference is in the scaling factors\\nwhere gradFU and gradFV use S T and S while those in Algorithm 2 use S ?1 and S ?T .\\nAssume that S is a diagonal matrix which can always be obtained by rotating U and V appropriately.\\nF (U, V ) would change more rapidly when the columns of U and V corresponding to larger entries\\n2\\nof S are changed. The rate of change of F would be approximately proportional to Sii\\nwhen the\\n2\\ni-th columns of U and V are changed, or in other words, S gives us an approximate second order\\ninformation of F at the current point (U, V ). This suggests that the level set of F should be similar to\\nan ?ellipse? with the shorter axes corresponding to the larger values of S. It is therefore compelling\\nto use a scaled metric on the Grassmann manifold.\\nConsider the inner product hW, W ? iD = Tr (DW T W ? ), where D ? Rr?r is a symmetric positive\\ndefinite matrix. We will derive the partial gradients of F on the Grassmann manifold endowed with\\nthis scaled inner product. According to [11], gradFU is the tangent vector of G(m, r) at U such that\\nTr (FUT W ) = h(gradFU )T , W iD ,\\n\\n(10)\\n\\nfor all tangent vectors W at U , where FU is the partial derivative of F with respect to U . Recall\\nthat the tangent vectors at U are those W ?s such that W T U = 0. The solution of (10) with the\\nconstraints that W T U = 0 and (gradFU )T U = 0 gives us the gradient based on the scaled metric,\\nwhich we will denote by grads FU and grads FV .\\ngrads FU (U, V )\\ngrads FV (U, V )\\n\\n=\\n=\\n\\n(I ? U U T )FU D?1 = (I ? U U T )P? (U SV T ? A)V SD?1 .\\nT\\n\\n(I ? V V )FV D\\n\\n?1\\n\\nT\\n\\n= (I ? V V )P? (U SV\\n\\nT\\n\\nT\\n\\n? A) U SD\\n\\n?1\\n\\n(11)\\n.\\n\\n(12)\\n\\nNotice the additional scaling D appearing in these scaled gradients. Now if we use D = S 2 (still\\nwith the assumption that S is diagonal) as suggested by the arguments above on the approximate\\nshape of the level set of F , we will have grads FU (U, V ) = (I ? U U T )P? (U SV T ? A)V S ?1 and\\ngrads FV (U, V ) = (I ? V V T )P? (U SV T ? A)T U S ?1 (note that S depends on U and V ).\\n4\\n\\n\\fIf S is not diagonalized, we use SS T and S T S to derive grads FU and grads FV respectively, and the\\nscalings appear exactly as in (3) and (4).\\ngrads FU (U, V )\\ngrads FV (U, V )\\n\\n=\\n=\\n\\n(I ? U U T )P? (U SV T ? A)V S ?1\\nT\\n\\n(I ? V V )P? (U SV\\n\\nT\\n\\nT\\n\\n? A) U S\\n\\n(13)\\n\\n?T\\n\\n(14)\\n\\nThis scaling can be interpreted as an adaptive preconditioning step similar to those that are popular\\nin the scientific computing literature [4]. As will be shown in our experiments, this scaled gradient\\ndirection outperforms canonical gradient directions especially for ill-conditioned matrices.\\nThe optimization framework on matrix manifolds allows to define several elements of the manifold\\nin a flexible way. Here, we use the scaled-metric to obtain a good descent direction, while other\\noperations on the manifold can be based on the canonical metric which has simple and efficient\\ncomputational forms. The next two sections describe algorithms using scaled-gradients.\\n3.2\\n\\nGradient descent algorithms on the Grassmann manifold\\n\\nGradient descent algorithms on matrix manifolds are based on the update\\nUi+1 = R(Ui + ti Wi )\\n\\n(15)\\n\\nwhere Wi is the gradient-related search direction, ti is the step size and R(U ) is a retraction on the\\nmanifold which defines a projection of U onto the manifold [1]. We use R(U ) = span (U ) as the\\nretraction on the Grassmann manifold where span (U ) is represented by qf(U ), which is the Q factor\\nin the QR factorization of U . Optimization on the product of two Grassmann manifolds can be done\\nby treating each component as a coordinate component.\\nThe step size t can be computed in several ways, e.g., by a simple back-tracking method to find the\\npoint satisfying the Armijo condition [3]. Algorithm 3 is an outline of our gradient descent method\\n(i)\\n(i)\\nfor matrix completion. We let grads FU ? grads FU (Ui , Vi ) and grads FV ? grads FV (Ui , Vi ). In\\nline 5, the exact Si+1 which realizes F (Ui+1 , Vi+1 ) can be computed according to (6). A direct\\nmethod to solve (6) costs O(|?|r4 ). Alternatively, Si+1 can be computed approximately and we\\nfound that (5) is fast (O((|?| + m + n)r2 )) and gives the same convergence speed. If (5) fails\\nto yield good enough progress, we can always switch back to (6) and compute Si+1 exactly. The\\nsubspace iteration and LMaFit can be seen as relaxed versions of this gradient descent procedure.\\nThe next section goes further and described the conjugate gradient iteration.\\nAlgorithm 3 G RADIENT DESCENT WITH SCALED - GRADIENT ON THE G RASSMANN MANIFOLD .\\nInput: Matrix A? , ?, and number r.\\nOutput: U and V which minimize F (U, V ), and S which realizes F (U, V ).\\n1: Initialize orthonormal matrices U0 and V0 .\\n2: for i = 0,1,2,... do\\n(i)\\n(i)\\n3:\\nCompute grads FU and grads FV according to (13) and (14).\\n4:\\nFind an appropriate step size ti and compute\\n(i)\\n\\n(i)\\n\\n(Ui+1 , Vi+1 ) = (qf(Ui ? ti grads FU ), qf(Vi ? ti grads FV ))\\n5:\\nCompute Si+1 according to (6) (exact) or (5) (approximate).\\n6: end for\\n\\n3.3\\n\\nConjugate gradient method on the Grassmann manifold\\n\\nIn this section, we describe the conjugate gradient (CG) method on the Grassmann manifold based\\non the scaled gradients to solve the matrix completion problem. The main additional ingredient we\\nneed is vector transport which is used to transport the old search direction to the current point on the\\nmanifold. The transported search direction is then combined with the scaled gradient at the current\\npoint, e.g. by Polak-Ribiere formula (see [11]), to derive the new search direction. After this, a line\\nsearch procedure is performed to find the appropriate step size along this search direction.\\nVector transport can be defined using the Riemann connection, which in turn is defined based on the\\nRiemann metric [1]. As mentioned at the end of Section 3.1, we will use the canonical metric to\\n5\\n\\n\\fderive vector transport when considering the natural quotient manifold structure of the Grassmann\\nmanifold. The tangent W ? at U will be transported to U + W as TU +W (W ? ) where TU (W ? ) =\\n(I ? U U T )W ? . Algorithm 4 is a sketch of the resulting conjugate gradient procedure.\\nAlgorithm 4 C ONJUGATE GRADIENT WITH SCALED - GRADIENT ON THE G RASSMANN MANIFOLD .\\nInput: Matrix A? , ?, and number r.\\nOutput: U and V which minimize F (U, V ), and S which realizes F (U, V ).\\n1: Initialize orthonormal matrices U0 and V0 .\\n(0)\\n(0)\\n2: Compute (?0 , ?0 ) = (grads FU , grads FV ).\\n3: for i = 0,1,2,... do\\n4:\\nCompute a step size ti and compute (Ui+1 , Vi+1 ) = (qf(Ui + ti ?i ), qf(Vi + ti ?i ))\\n5:\\nCompute ?i+1 (Polak-Ribiere) and set\\n(i)\\n\\n(i)\\n\\n(?i+1 , ?i+1 ) = (?grads FU + ?i+1 TUi+1 (?i ), ?grads FV + ?i+1 TVi+1 (?i ))\\n6:\\nCompute Si+1 according to (6) or (5).\\n7: end for\\n\\n4\\n\\nConvergence and exact recovery of scaled-gradient descent methods\\n\\nLet A = U? ?? V?T be the singular value decomposition of A, where U? ? Rm?r , V? ? Rn?r and\\n?? ? Rr?r . Let us also denote z = (U, V ) a point on G(m, r) ? G(n, r). Clearly, z? = (U? , V? )\\nis a minimum of F . Assume that A is incoherent [14]; A has bounded entries and the minimum\\nsingular value of A is bounded away from 0. Let ?(A) be the condition number of A. It is shown\\nthat, if the number of observed entries is of order O(max{?(A)2 n log n, ?(A)6 n}) then, with high\\nprobability, F is well approximated by a parabola and z? is the unique stationary point of F in a\\nsufficiently small neighborhood of z? ([14, Lemma 6.4&6.5]). From these observations, given an\\ninitial point that is sufficiently close to z? , a gradient descent procedure on F (with an additional\\nregularization term to keep the intermediate points incoherent) converges to z? and exact recovery\\nis obtained. The singular value decomposition of a trimmed version of the observerd matrix A? can\\ngive us the initial point that ensures convergence. The readers are referred to [14] for details.\\n(i) 2\\n(i) 2\\nPm\\nPn\\nFrom [14], let G(U, V ) = i=1 G1 ( kUCinck ) + i=1 G1 ( kVCinck ), where G1 (x) = 0 if x ? 1\\n2\\n\\nand G1 (x) = e(x?1) ? 1 otherwise; Cinc is a constant depending on the incoherence assumptions.\\nWe consider the regularized version of F : F? (U, V ) = F (U, V ) + ?G(U, V ), where ? is chosen\\nappropriately so that U and V remain incoherent during the execution of the algorithm. We can see\\nthat z? is also the minimum of F? . We will now show that the scaled-gradients of F? are well-defined\\nduring the iterations and they are indeed descent directions of F? and only vanish at z? . As a result,\\nthe scaled-gradient-based methods can inherit all the convergence results in [14].\\nFirst, S must be non-singular during the iterations for the scaled-gradients to be well-defined. As a\\ncorollary of Lemma 6.4 in [14], the extreme singular values of any intermediate S are bounded by\\n?\\n?\\n?\\n?\\n. The second\\nextreme singular values ?min\\nand ?max\\nof ?? : ?max ? 2?max\\nand ?min ? 12 ?min\\ninequality implies that S is well-conditioned during the iterations.\\nThe scaled-gradient is the descent direction of F? as a direct result from the fact that it is indeed the gradient of F? based on a non-canonical metric. Moreover, by Lemma 6.5 in [14],\\n?\\nkgradF? (z)k2 ? Cn?2 (?min\\n)4 d(z, z? )2 for some constant C, where k.k and d(., .) are the canonical\\nnorm and distance on the Grassmann manifold respectively. Based on this, a similar lower bound of\\nkgrads F? k can be derived. Let D1 = SS T and D2 = S T S be the scaling matrices. Then,\\nkgrad F? (z)k2 = kgradF?U (z)D?1 k2 + kgradF?V (z)D?1 k2\\ns\\n\\n?\\n?\\n\\nF\\nF\\n2\\n1\\n2\\n?2\\n2\\n?\\n?\\n?max (kgradFU (z)kF + kgradFV (z)kF )\\n?\\n(2?max\\n)?2 kgradF? (z)k2\\n?\\n?\\n?\\n?\\n(2?max\\n)?2 Cn?2 (?min\\n)4 d(z, z? )2 = C(?min\\n)4 (2?max\\n)?2 n?2 d(z, z? )2 .\\n\\n?\\nTherefore, the scaled gradients only vanish at z? which means the scaled-gradient descent procedure\\nmust converge to z? , which is the exact solution [3].\\n6\\n\\n\\f5\\n\\nExperiments and results\\n\\nThe proposed algorithms were implemented in Matlab with some mex-routines to perform matrix\\nmultiplications with sparse masks. For synthesis data, we consider two cases: (1) fully random\\nlow-rank matrices, A = randn(m, r) ? randn(r, n) (in Matlab notations) whose singular values\\ntend to be roughly the same; (2) random low-rank matrices with chosen singular values by letting\\nU = qf(randn(m, r)), V = qf(randn(n, r)) and A = U SV T where S is a diagonal matrix with\\nchosen singular values. The initializations of all methods are based on the SVD of A? .\\nFirst, we illustrate the improvement of scaled gradients over canonical gradients for steepest descent\\nand conjugate gradient methods on 5000 ? 5000 matrices with rank 5 (Figure 1). Note that CanonGrass-Steep is OptSpace with our implementation. In this experiment, Si is obtained exactly using\\n(6). The time needed for each iteration is roughly the same for all methods so we only present the\\nresults in terms of iteration counts. We can see that there are some small improvements for the fully\\nrandom case (Figure 1a) since the singular values are roughly the same. The improvement is more\\nsubstantial for matrices with larger condition numbers (Figure 1b).\\n5000x5000 ? Rank 5 ? 1.0% observed entries\\nSingular values [4774, 4914, 4979, 5055, 5146]\\n\\n5000x5000 ? Rank 5 ? 1.0% observed entries\\nSingular values [1000, 2000, 3000, 4000, 5000]\\n\\n0\\n\\n0\\n\\n?2\\n\\n?4\\n\\n?5\\n\\nRMSE (log?scale)\\n\\nRMSE (log?scale)\\n\\nCanon?Grass?Steep\\nCanon?Grass?CG\\nScaled?Grass?Steep\\nScaled?Grass?CG\\n\\n?6\\n\\n?8\\n\\nCanon?Grass?Steep\\nCanon?Grass?CG\\nScaled?Grass?Steep\\nScaled?Grass?CG\\n\\n?10\\n?10\\n\\n?12\\n\\n?15\\n\\n10\\n\\n20\\n\\n30\\n\\n40\\n\\n50\\nIteration count\\n\\n60\\n\\n70\\n\\n80\\n\\n?14\\n\\n90\\n\\n(a)\\n\\n20\\n\\n40\\n\\n60\\n\\n80\\n\\n100\\n120\\nIteration count\\n\\n140\\n\\n160\\n\\n180\\n\\n200\\n\\n(b)\\n\\nFigure 1: Log-RMSE for fully random matrix (a) and random matrix with chosen spectrum (b).\\nNow, we compare the relaxed version of the scaled conjugate gradient which uses (5) to compute Si\\n(ScGrass-CG) to LMaFit [23], Riemann-CG [22], RTRMC2 [6] (trust region method with second\\norder information), SVP [12] and GROUSE [5] (Figure 2). These methods are also implemented in\\nMatlab with mex-routines similar to ours except for GROUSE which is entirely in Matlab (Indeed\\nGROUSE does not use sparse matrix multiplication as other methods do). The subspace iteration\\nmethod and the relaxed version of scaled steepest descent converge similarly to LMaFit, so we omit\\nthem in the graph. Note that each iteration of GROUSE in the graph corresponds to one pass over\\nthe matrix. It does not have exactly the same meaning as one iteration of other methods and is\\nmuch slower with its current implementation. We use the best step sizes that we found for SVP\\nand GROUSE. In terms of iteration counts, we can see that for the fully random case (upper row),\\nRTRMC2 is the best while ScGrass-CG and Riemann-CG converge reasonably fast. However, each\\niteraton of RTRMC2 is slower so in terms of time, ScGrass-CG and Riemann-CG are the fastest in\\nour experiments. When the condition number of the matrix is higher, ScGrass-CG converges fastest\\nboth in terms of iteration counts and execution time.\\nFinally, we test the algorithms on Jester-1 and MovieLens-100K datasets which are assumed to\\nbe low-rank matrices with noise (SVP and GROUSE are not tested because their step sizes need\\nto be appropriately chosen). Similarly to previous work, for the Jester dataset we randomly select 4000 users and randomly withhold 2 ratings for each user for testing. For the MovieLens\\ndataset, we use the common dataset prepared by [16], and keep 50% for training and 50% for\\ntesting. We run 100 different randomizations of Jester and 10 randomizations of MovieLens and\\naverage the results. We stop all methods early, when the change of RMSE is less than 10?4 , to\\navoid overfitting. All methods stop well before one minute. The Normalized Mean Absolute Errors\\n(NMAEs) [13] are reported in Table 1. ScGrass-CG is the relaxed scaled CG method and ScGrassCG-Reg is the exact scaled CG method using a spectral-regularization version of F proposed in\\n7\\n\\n\\f10000x10000 ? Rank 10 ? 0.5% observed entries\\nSingular values [9612,9717,9806,9920,9987,10113,10128,10226,10248,10348]\\n\\n10000x10000 ? Rank 10 ? 0.5% observed entries\\nSingular values [9612,9717,9806,9920,9987,10113,10128,10226,10248,10348]\\n\\n2\\n\\n2\\nGROUSE\\nSVP\\n\\n0\\n\\n0\\nSVP\\n?2\\n\\nRMSE (log?scale)\\n\\nRMSE (log?scale)\\n\\n?2\\n?4\\n?6\\n?8\\n\\n?6\\n?8\\n?10\\n\\nLMaFit\\n?10\\n\\n?12\\n\\nScGrass?CG\\n\\nScGrass?CG\\n\\n?12 RTRMC2\\n?14\\n\\n?4\\n\\n?14\\n\\nRiemannCG\\n20\\n\\n40\\n\\nGROUSE\\n80\\n100\\n120\\nIteration count\\n\\n60\\n\\n140\\n\\n160\\n\\n180\\n\\n?16\\n\\n200\\n\\nLMaFit\\n\\nRiemann?CG\\n0\\n\\n10000x10000 ? Rank 10 ? 0.5% observed entries\\nSingular values [1000,2000,3000,4000,5000,6000,7000,8000,9000,10000]\\n\\n5\\n\\n10\\n\\n15\\n\\nRTRMC2\\n20\\n\\n25\\nTime [s]\\n\\n30\\n\\n35\\n\\n40\\n\\n45\\n\\n50\\n\\n10000x10000 ? Rank 10 ? 0.5% observed entries\\nSingular values [1000,2000,3000,4000,5000,6000,7000,8000,9000,10000]\\n\\n2\\n\\n2\\n\\n0\\n\\n0\\n\\nSVP\\n\\nSVP\\nGROUSE\\n\\n?2\\n\\nLMaFit\\n\\nGROUSE\\n\\n?2\\nRMSE (log?scale)\\n\\nRMSE (log?scale)\\n\\nLMaFit\\n\\nRTRMC2\\n\\n?4\\n?6\\n?8\\n\\nRTRMC2\\n\\n?4\\n?6\\n?8\\n\\nRiemann?CG\\n?10\\n\\nRiemann?CG\\n\\n?10\\n\\nScGrass?CG\\n?12\\n\\n?12\\n\\nScGrassCG\\n?14\\n\\n50\\n\\n100\\n\\n150\\nIteration count\\n\\n200\\n\\n250\\n\\n?14\\n\\n300\\n\\n0\\n\\n10\\n\\n20\\n\\n30\\n\\n40\\n\\n50\\nTime [s]\\n\\n60\\n\\n70\\n\\n80\\n\\n90\\n\\n100\\n\\nFigure 2: Log-RMSE. Upper row is fully random, lower row is random with chosen singular values.\\nRank\\n5\\n7\\n5\\n7\\n\\nScGrass-CG\\n0.1588\\n0.1584\\n0.1808\\n0.1832\\n\\nScGrass-CG-Reg\\n0.1588\\n0.1584\\n0.1758\\n0.1787\\n\\nLMaFit\\n0.1588\\n0.1581\\n0.1828\\n0.1836\\n\\nRiemann-CG\\n0.1591\\n0.1584\\n0.1781\\n0.1817\\n\\nRTRMC2\\n0.1588\\n0.1583\\n0.1884\\n0.2298\\n\\nTable 1: NMAE on Jester dataset (first 2 rows) and MovieLens 100K. NMAEs for a random guesser\\nare 0.33 on Jester and 0.37 on MovieLens 100K.\\n[13]: F? (U, V ) = minS (1/2)(kP? (U SV T ? A)k + ?kSk2F ). All methods perform similarly and\\ndemonstrate overfitting when k = 7 for MovieLens. We observe that ScGrass-CG-Reg suffers the\\nleast from overfitting thanks to its regularization. This shows the importance of regularization for\\nnoisy matrices and motivates future work in this direction.\\n\\n6\\n\\nConlusion and future work\\n\\nThe gradients obtained from a scaled metric on the Grassmann manifold can result in improved\\nconvergence of gradient methods on matrix manifolds for matrix completion while maintaining\\ngood global convergence and exact recovery guarantees. We have established a connection between\\nscaled gradient methods and subspace iteration method for matrix completion. The relaxed versions\\nof the proposed gradient methods, adapted from the subspace iteration, are faster than previously\\ndiscussed algorithms, sometimes much faster depending on the conditionining of the data matrix.\\nIn the future, we will investigate if these relaxed versions achieve similar performance guarantees.\\nWe are also interested in exploring ways to regularize the relaxed versions to deal with noisy data.\\nThe convergence condition of OptSpace depends on ?(A)6 and weakening this dependency for the\\nproposed algorithms is also an interesting future direction.\\n8\\n\\n\\fAcknowledgments\\nThis work was supported by NSF grants DMS-0810938 and DMR-0940218.\\n\\nReferences\\n[1] P.-A. Absil, R. Mahony, and R. Sepulchre. Optimization Algorithms on Matrix Manifolds. Princeton\\nUniversity Press, Princeton, NJ, 2008.\\n[2] Y. Amit, M. Fink, N. Srebro, and S. Ullman. Uncovering shared structures in multiclass classification. In\\nProceedings of the 24th international conference on Machine learning, ICML ?07, pages 17?24, 2007.\\n[3] L. Armijo. Minimization of functions having Lipschitz continuous first partial derivatives. Pacific Journal\\nof Mathematics, 16(1):1?3, 1966.\\n[4] J. Baglama, D. Calvetti, G. H. Golub, and L. Reichel. Adaptively preconditioned GMRES algorithms.\\nSIAM J. Sci. Comput., 20(1):243?269, December 1998.\\n[5] L. Balzano, R. Nowak, and B. Recht. Online identification and tracking of subspaces from highly incomplete information. In Proceedings of Allerton, September 2010.\\n[6] N. Boumal and P.-A. Absil. Rtrmc: A riemannian trust-region method for low-rank matrix completion.\\nIn NIPS, 2011.\\n[7] J-F. Cai, E. J. Cand`es, and Z. Shen. A singular value thresholding algorithm for matrix completion. SIAM\\nJournal on Optimization, 20(4):1956?1982, 2010.\\n[8] E. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion, 2009.\\n[9] P. Chen and D. Suter. Recovering the Missing Components in a Large Noisy Low-Rank Matrix: Application to SFM. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(8):1051?1063,\\n2004.\\n[10] W. Dai, E. Kerman, and O. Milenkovic. A geometric approach to low-rank matrix completion. IEEE\\nTransactions on Information Theory, 58(1):237?247, 2012.\\n[11] A. Edelman, T. Arias, and S. T. Smith. The geometry of algorithms with orthogonality constraints. SIAM\\nJ. Matrix Anal. Appl, 20:303?353, 1998.\\n[12] P. Jain, R. Meka, and I. S. Dhillon. Guaranteed rank minimization via singular value projection. In NIPS,\\npages 937?945, 2010.\\n[13] R. Keshavan, A. Montanari, and S. Oh. Matrix completion from noisy entries. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing\\nSystems 22, pages 952?960. 2009.\\n[14] R. H. Keshavan, S. Oh, and A. Montanari. Matrix completion from a few entries. CoRR, abs/0901.3150,\\n2009.\\n[15] S. Ma, D. Goldfarb, and L. Chen. Fixed point and bregman iterative methods for matrix rank minimization. Math. Program., 128(1-2):321?353, 2011.\\n[16] B. Marlin. Collaborative filtering: A machine learning perspective, 2004.\\n[17] R. Mazumder, T. Hastie, and R. Tibshirani. Spectral regularization algorithms for learning large incomplete matrices. J. Mach. Learn. Res., 11:2287?2322, August 2010.\\n[18] B. Recht. A simpler approach to matrix completion. CoRR, abs/0910.0651, 2009.\\n[19] J. D. M. Rennie and N. Srebro. Fast maximum margin matrix factorization for collaborative prediction.\\nIn In Proceedings of the 22nd International Conference on Machine Learning (ICML, pages 713?719.\\nACM, 2005.\\n[20] Y. Saad. Numerical Methods for Large Eigenvalue Problems- classics edition. SIAM, Philadelpha, PA,\\n2011.\\n[21] N. Srebro and T. Jaakkola. Weighted low-rank approximations. In In 20th International Conference on\\nMachine Learning, pages 720?727. AAAI Press, 2003.\\n[22] B. Vandereycken. Low-rank matrix completion by riemannian optimization. Technical report, Mathematics Section, Ecole Polytechnique Federale de de Lausanne, 2011.\\n[23] Z. Wen, W. Yin, and Y. Zhang. Solving a low-rank factorization model for matrix completion using a\\nnon-linear successive over-relaxation algorithm. In CAAM Technical Report. Rice University, 2010.\\n\\n9\\n\\n\\f\",\n          \"Self-Organizing and Adaptive Algorithms for\\nGeneralized Eigen-Decomposition\\nChanchal Chatterjee\\n\\nVwani P. Roychowdhury\\n\\nNewport Corporation\\n1791 Deere Avenue, Irvine, CA 92606\\n\\nElectrical Engineering Department\\nUCLA, Los Angeles, CA 90095\\n\\nABSTRACT\\nThe paper is developed in two parts where we discuss a new approach\\nto self-organization in a single-layer linear feed-forward network. First,\\ntwo novel algorithms for self-organization are derived from a two-layer\\nlinear hetero-associative network performing a one-of-m classification,\\nand trained with the constrained least-mean-squared classification error\\ncriterion. Second, two adaptive algorithms are derived from these selforganizing procedures to compute the principal generalized\\neigenvectors of two correlation matrices from two sequences of\\nrandom vectors. These novel adaptive algorithms can be implemented\\nin a single-layer linear feed-forward network. We give a rigorous\\nconvergence analysis of the adaptive algorithms by using stochastic\\napproximation theory. As an example, we consider a problem of online\\nsignal detection in digital mobile communications.\\n\\n1. INTRODUCTION\\nWe study the problems of hetero-associative trammg, linear discriminant analysis,\\ngeneralized eigen-decomposition and their theoretical connections. The paper is divided\\ninto two parts. In the first part, we study the relations between hetero-associative training\\nwith a linear feed-forward network, and feature extraction by the linear discriminant\\nanalysis (LOA) criterion. Here we derive two novel algorithms that unify the two\\nproblems. In the second part, we generalize the self-organizing algorithm for LOA to\\nobtain adaptive algorithms for generalized eigen-decomposition, for which we provide a\\nrigorous proof of convergence by using stochastic approximation theory.\\n\\n1.1 HETERO-ASSOCIATION AND LINEAR DISCRIMINANT ANALYSIS\\nIn this discussion, we consider a special case of hetero-association that deals with the\\nclassification problems. Here the inputs belong to a finite m-set of pattern classes, and the\\n\\n\\fSelf-Organizing and Adaptive Generalized Eigen-Decomposition\\n\\n397\\n\\noutputs indicate the classes to which the inputs belong. Usually, the ith standard basis\\nvector ei is chosen to indicate that a particular input vector x belongs to class i.\\nThe LDA problem, on the other hand, aims at projecting a multi-class data in a lower\\ndimensional subspace such that it is grouped into well-separated clusters for the m\\nclasses. The method is based upon a set of scatter matrices commonly known as the\\nmixture scatter Sm and between class scatter Sb (Fukunaga, 1990). These matrices are\\nused to formulate criteria such as tr(Sm-ISb) and det(Sb)1 det(Sm) which yield a linear\\ntransform <1> that satisfy the generalized eigenvector problem Sb<1>=Sm<1>A, where A is the\\ngeneralized eigenvalue matrix. If Sm is positive definite, we obtain a <1> such that <1>TSm<1>\\n=1 and <1>TSb<1>=A. Furthermore, the significance of each eigenvector (for class\\nseparability) is determined by the corresponding generalized eigenvalue.\\nA relation between hetero-association and LDA was demonstrated by Gallinari et al.\\n(1991). Their work made explicit that for a linear multi-layer perceptron performing a\\none-from-m classification that minimized the total mean square error (MSE) at the\\nnetwork output, also maximized a criterion det(Sb)/det(Sm) for LDA at the final hidden\\nlayer. This study was generalized by Webb and Lowe (1990) by using a nonlinear\\ntransform from the input data to the final hidden units, and a linear transform in the final\\nlayer. This has been further generalized by Chatterjee and Roychowdhury (1996) by\\nincluding the Bayes cost for misclassification into the criteria tr(Sm-ISb).\\nAlthough the above studies offer useful insights into the relations between heteroassociation and LDA, they do not suggest an algorithm to extract the optimal LDA\\ntransform <1>. Since the criteria for class separability are insensitive to multiplication by\\nnonsingular matrices, the above studies suggest that any training procedure that\\nminimizes the MSE at the network output will yield a nonsingular transformation of <1>;\\ni.e., we obtain Q<1> where Q is a nonsingular matrix. Since Q<1> does not satisfy the\\ngeneralized eigenvector problem Sb<1>=Sm<1>A for any arbitrary nonsingular matrix Q, we\\nneed to determine an algorithm that will yield Q=I.\\nIn order to obtain the optimum linear transform <1>, we constrain the training of a twolayer linear feed-forward network, such that at convergence, the weights for the first\\nlayer simultaneously diagonalizes Sm and Sb. Thus, the hetero-associative network is\\ntrained by minimizing a constrained MSE at the network output. This training procedure\\nyields two novel algorithms for LDA.\\n1.2 LDA AND GENERALIZED EIGEN-DECOMPOSITION\\n\\nSince the LDA problem is a generalized eigen-decomposition problem for the\\nsymmetric-definite case, the self-organizing algorithms derived from the heteroassociative networks lead us to construct adaptive algorithms for generalized eigendecomposition. Such adaptive algorithms are required in several applications of image\\nand signal processing. As an example, we consider the problem of online interference\\ncancellation in digital mobile communications.\\nSimilar to the LDA problem Sb<1>=Sm<1>A, the generalized eigen-decomposition problem\\nA<1>=B<1>A involves the matrix pencil (A ,B), where A and B are assumed to be real,\\nsymmetric and positive definite. Although a solution to the problem can be obtained by a\\nconventional method, there are several applications in image and signal processing where\\nan online solution of generalized eigen-decomposition is desired. In these real-time\\nsituations, the matrices A and B are themselves unknown. Instead, there are available two\\n\\n\\f398\\n\\nC. Chatterjee and V. P Roychowdhury\\n\\nsequences of random vectors {xk} and {Yk} with limk~ooE[x~/J =A and limk~oo\\nE[Yky/'I=B, where xk and Yk represent the online observations of the application. For\\nevery sample (x/C>Yk), we need to obtain the current estimates <1>k and Ak of <1> and A\\nrespectively, such that <1>k and Ak converge strongly to their true values.\\nThe conventional approach for evaluating <1> and A requires the computation of (A,B)\\nafter collecting all of the samples, and then the application of a numerical procedure; i.e.,\\nthe approach works in a batch fashion. There are two problems with this approach.\\nFirstly, the dimension of the samples may be large so that even if all of the samples are\\navailable, performing the generalized eigen-decomposition may take prohibitively large\\namount of computational time. Secondly, the conventional schemes can not adapt to slow\\nor small changes in the data. So the approach is not suitable for real-time applications\\nwhere the samples come in an online fashion.\\nAlthough the adaptive generalized eigen-decomposition algorithms are natural\\ngeneralizations of the self-organizing algorithms for LDA, their derivations do not\\nconstitute a proof of convergence. We, therefore, give a rigorous proof of convergence\\nby stochastic approximation theory, that shows that the estimates obtained from our\\nadaptive algorithms converge with probability one to the generalized eigenvectors.\\nIn summary, the study offers the following contributions: (1) we present two novel\\nalgorithms that unify the problems of hetero-associative training and LDA feature\\nextraction; and (2) we discuss two single-stage adaptive algorithms for generalized eigendecomposition from two sequences of random vectors.\\nIn our experiments, we consider an example of online interference cancellation in digital\\nmobile communications. In this problem, the signal from a desired user at a far distance\\nfrom the receiver is corrupted by another user very near to the base. The optimum linear\\ntransform w for weighting the signal is the first principal generalized eigenvector of the\\nsignal correlation matrix with respect to the interference correlation matrix. Experiments\\nwith our algorithm suggest a rapid convergence within four bits of transmitted signal, and\\nprovides a significant advantage over many current methods.\\n\\n2. HETERO-ASSOCIATIVE TRAINING AND LDA\\nWe consider a two-layer linear network performing a one-from-m classification. Let XE\\n9t n be an input to the network to be classified into one out of m classes ro l'''''ro m. If x E ro j\\nthen the desired output d=e j (ith std. basis vector). Without loss of generality, we assume\\nthe inputs to be a zero-mean stationary process with a nonsingular covariance matrix.\\n\\n2.1 EXTRACTING THE PRINCIPAL LDA COMPONENTS\\nIn the two-layer linear hetero-associative network, let there be p neurons in the hidden\\nlayer, and m output units. The aim is to develop an algorithm so that indi\\\",idual weight\\nvectors for the first layer converge to the first p~m generalized eigenvectors\\ncorresponding to the p significant generalized eigenvalues arranged in decreasing order.\\nLet WjE9t n (i=I, ... ,n) be the weight vectors for the input layer, and VjE9t m (i=I, ... ,m) be\\nthe weight vectors for the output layer.\\nThe neurons are trained sequentially; i.e., the training of the jlh neuron is started only\\nafter the weight vector of the (j_I)fh neuron has converged. Assume that all the j-I\\nprevious neurons have already been trained and their weights have converged to the\\n\\n\\f399\\n\\nSelf-Organizing and Adaptive Generalized Eigen-Decomposition\\n\\noptimal weight vectors wi for i E (1 J-l]. To extract the J'h generalized eigenvector in the\\noutput of the /h neuron, the updating model for this neuron should be constructed by\\nsubtracting the results from all previously computed j-I generalized eigenvectors from\\nthe desired output dj as below\\n-\\n\\ndj\\n\\n= dj\\n\\nj-I\\n-\\n\\nT\\n\\nL vi W i x.\\n\\n(1)\\n\\ni=1\\n\\nThis process is equivalent to the deflation of the desired output.\\nThe scatter matrices Sm and Sb can be obtained from x and d as Sm=E[xx T] and Sb=\\nMMT, where M=E[xd1). We need to extract the j1h LOA transform Wj that satisfies the\\ngeneralized eigenvector equation SbWj=AlmWj such that Aj is the J'h largest generalized\\neigenvalue. The constrained MSE criterion at the network output is\\nJh,Vj\\n\\n)=,lld j <~:v;wTx-vjWJxr]+\\n\\np{wJSmw j -I).\\n\\n(2)\\n\\nUsing (2), we obtain the update equation for Wj as\\n\\nw(J)\\n\\nhI\\n\\n= w(J)\\n+ {Mv(J) k\\nk\\n\\nS w(J)(w(J)T Mv(J?)- S j~1 w(J)v(i)T v(J?)\\nm k\\nk\\nk\\nm L.. k k\\nk .\\n;=1\\n\\n(3)\\n\\nDifferentiating (2) with respect to vi' and equating it to zero, we obtain the optimum\\nvalue ofvj as MTWj . Substituting this Vj in (3) we obtain\\n\\nw(J) = w(J) +\\nk+1\\nk\\n\\n{s\\n\\nw(J) - S w(J)(w(J)TS w(J?) - S j~1 wU)w(i)T S w(J?)\\nb k\\nm k\\nk\\nb k\\nm L.. k k b k .\\n\\n(4)\\n\\ni=1\\n\\nLet Wk be the matrix whose ith column is w~). Then (4) can be written in matrix form as\\nWk+1\\n\\n= Wk + r{SbWk -SmWkU~W[SbWk\\n\\np,\\n\\n(5)\\n\\nwhere UT[?] sets all elements below the diagonal of its matrix argument to zero, thereby\\nmaking it upper triangular.\\n\\n2.2 ANOTHER SELF-ORGANIZING ALGORITHM FOR LDA\\nIn the previous analysis for a two-layer linear hetero-associative network, we observed\\nthat the optimum value for V=WTM, where the jlh column of Wand row of V are formed\\nby Wi and Vi respectively. It is, therefore, worthwhile to explore the gradient descent\\nprocedure on the error function below instead of (2)\\nJ(W)\\n\\n=\\n\\nE[lld- MTWWTxI12}\\n\\n(6)\\n\\nBy differentiating this error function with respect to W, and including the deflation\\nprocess, we obtain the following update procedure for W instead of (5)\\nWk+1\\n\\n= Wk + ~2SbWk\\n\\n- Sm Wk UT [W[ SbWk ] - SbWkUT[ W[ SmWk]).\\n\\n(7)\\n\\n3. LDA AND GENERALIZED EIGEN-DECOMPOSITION\\nSince LOA consists of solving the generalized eigenvector problem Sb<P=Sm<PA, we can\\nnaturally generalize algorithms (5) and (7) to obtain adaptive algorithms for the\\ngeneralized eigen-decomposition problem A<P=B<PA, where A and B are assumed to be\\nsymmetric and positive definite. Here, we do not have the matrices A and B. Instead,\\n\\n\\f400\\n\\nC. Chatterjee and V. P. Roychowdhury\\n\\nthere are available two sequences of random vectors {xk} and {Yk} with limk~ooE[xp/]\\n=A and limk~~[Yky/]=B, where xk and Yk represent the online observations.\\nFrom (5), we obtain the following adaptive algorithm for generalized eigendecomposition\\n(8)\\n\\nHere {17k} is a sequence of scalar gains, whose properties are described in Section 4. The\\nsequences {Ak} and {B k} are instantaneous values of the matrices A and B respectively.\\nAlthough the Ak and Bk values can be obtained from xk and Yk as xp/ and YkY/\\nrespectively, our algorithm requires that at least one of the {Ak} or {B k} sequences have a\\ndominated convergence property. Thus, the {Ak} and {Bk } sequences may be obtained\\nfrom xp/ and YkY/ from the following algorithms\\n\\nAk\\n\\n= Ak_1 +Yk(XkXk -A k- I )\\n\\nand Bk\\n\\n= Bk- I\\n\\n+Yk(YkYk -Bk-d,\\n\\n(9)\\n\\nwhere Ao and Bo are symmetric, and {Yk} is a scalar gain sequence.\\nAs done before, we can generalize (7) to obtain the following adaptive algorithm for\\ngeneralized eigen-decomposition from a sequence of samples {Ak} and {Bk}\\n\\nWk+1\\n\\n= Wk + l7k(2A k Wk -\\n\\nBkWkUT[ W[ AkWk ] - AkWkUT[ W[ BkWk ]).\\n\\n(10)\\n\\nAlthough algorithms (8) and (10) were derived from the network MSE by the gradient\\ndescent approach, this derivation does not guarantee their convergence. In order to prove\\ntheir convergence, we use stochastic approximation theory. We give the convergence\\nresults only for algorithm (l0).\\n\\n4. STOCHASTIC APPROX. CONVG. PROOF FOR ALG. (10)\\nIn order to prove the con vergence of (10), we use stochastic approximation theory due to\\nLjung (1977). In stochastic approximation theory, we study the asymptotic properties of\\n(10) in terms of the ordinary differential equation (ODE)\\n\\n~ W(t)= 1!!! E[2AkW -\\n\\nBkWUT[ W T AkW]- AkWUT[ W T BkW]],\\n\\nwhere W(t) is the continuous time counterpart of Wk with t denoting continuous time. The\\nmethod of proof requires the following steps: (1) establishing a set of conditions to be\\nimposed on A, B, A\\\", B\\\", and 17\\\", (2) finding the stable stationary points of the ODE; and\\n(3) demonstrating that Wk visits a compact subset of the domain of attraction of a stable\\nstationary point infinitely often.\\nWe use Theorem 1 of Ljung (1977) for the convergence proof. The following is a general\\nset of assumptions for the convergence proof of (10):\\nAssumption (AI). Each xk and Yk is bounded with probability one, and limk~ooE[xp/]\\n= A and limk~ooE[y kY k1) = B, where A and B are positive definite.\\nAssumption (A2). {l7kE9t+} satisfies l7kJ..O, Lk=Ol7k =OO,Lk=Ol7k <00 for some r>1 and\\n\\nlimk~oo sup(l7i l -l7i~l) <00.\\nAssumption (A3). The p largest generalized eigenvalues of A with respect to B are each\\nof unit mUltiplicity.\\nLemma 1. Let Al and A2 hold. Let w* be a locally asymptotically stable (in the sense of\\nLiapunov) solution to the ordinary differential equation (ODE):\\n\\n\\fSelf-Organizing and Adaptive Generalized Eigen-Decomposition\\n\\n~ W(t) = 2AW(t) -\\n\\nBW(t)U4W(t/ AW(t)] - AW(t)U4W(t/ BW(t)],\\n\\n401\\n\\n(11)\\n\\nwith domain of attraction D(W). Then if there is a compact subset S of D(W) such that\\n?\\nWk E S infinitely often, then we have Wk ~ W with probability one as k ~ 00.\\n\\nWe denote A\\\\ > ~ > ... > Ap ~ ... ~ An > 0 as the generalized eigenvalues of A with\\nrespect to B, and 4>; as the generalized eigenvector corresponding to A; such that 4>\\\\, ... ,4>n\\nare orthonormal with respect to B. Let <l>=[4>\\\\ ... 4>n l and A=diag(A\\\\, ... ,An ) denote the\\nmatrix of generalized eigenvectors and eigenvalues of A with respect to B. Note that if 4>;\\nis a generalized eigenvector, then d;4>; (ld;l= 1) is also a generalized eigenvector.\\nIn the next two lemmas, we first prove that all the possible equilibrium points ofthe ODE\\n(11) are up to an arbitrary permutation of the p generalized eigenvectors of A with\\nrespect to B corresponding to the p largest generalized eigenvalues. We next prove that\\nall these equilibrium points of the ODE (11) are unstable equilibrium points, except for\\n[d\\\\4>\\\\ ... dn4> nl, where Id;I=1 for i=I, ... ,p.\\nLemma 2. For the ordinary differential equation (11), let Al and A3 hold Then W=<l>DP\\nare equilibrium points of (11), where D=[D\\\\IOV is a nXp matrix with DI being a pXp\\ndiagonal matrix with diagonal elements d; such that Id;l= 1 or d;=O, and P is a nXn\\narbitrary permutation matrix.\\n?\\nLemma 3. Let Al and A3 hold Then W=<l>D (where D=[D\\\\101~ D\\\\ =diag(d\\\\, ...,dp )'\\nId;I=I) are stable equilibrium points of the ODE (11). In addition, W=<l>DP (d;=O for i~p\\nor P~J) are unstable equilibrium points of the ODE (11) .\\n?\\nLemma 4. For the ordinary differential equation (11) , let Al and A3 hold Then the\\npoints W=<l>D (where D=[D\\\\101~ D\\\\ =diag(d\\\\, ... ,dp )' Id;I=1 for i=I, ... ,p) are\\n?\\nasymptotically stable.\\nLemma 5. Let AI-A3 hold Then there exists a uniform upper boundfor 17k such that Wk\\nis uniformly bounded w.p . I .\\n\\n?\\n\\nThe convergence of alg. (10) can now be established by referring to Theorem 1 of Ljung.\\nTheorem 1. Let A I-A3 hold Assume that with probability one the process {Wk } visits\\ninfinitely often a compact subset of the domain of attraction of one of the asymptotically\\nstable points <l>D. Then with probability one\\nlim Wk = <l>D.\\nk~OCl\\n\\nProof. By Lemma 2, <l>D (ld;I=I) are asymptotically stable points of the ODE (11). Since\\nwe assume that {Wk } visits a compact subset of the domain of attraction of <l>D infmitely\\noften, Lemma 1 then implies the theorem.\\n?\\n\\n5. EXPERIMENT AL RESULTS\\nWe describe the performance of algorithms (8) and (10) with an example of online\\ninterference cancellation in a high-dimensional signal, in a digital mobile communication\\nproblem. The problem occurs when the desired user transmits a signal from a far distance\\nto the receiver, while another user simultaneously transmits very near to the base. For\\ncommon receivers, the quality of the received signal from the desired user is dominated\\nby interference from the user close to the base. Due to the high rate and large dimension\\nof the data, the system demands an accurate detection method for just a few data samples.\\n\\n\\fC. Chatterjee and V. P. Roychowdhury\\n\\n402\\n\\nIf we use conventional (numerical analysis) methods, signal detection will require a\\nsignificant part of the time slot allotted to a receiver, accordingly reducing the effective\\ncommunication rate. Adaptive generalized eigen-decomposition algorithms, on the other\\nhand, allow the tracking of slow changes, and directly performs signal detection.\\nThe details of the data model can be found in Zoltowski et al. (1996). In this application,\\nthe duration for each transmitted code is 127 IlS, within which we have lOllS of signal\\nand 1171ls of interference. We take 10 frequency samples equi-spaced between -O.4MHz\\nto +O.4MHz. Using 6 antennas, the signal and interference correlation matrices are of\\ndimension 60X60 in the complex domain.\\nWe use both algorithms (8) and (10) for the cancellation of the interference. Figure 1\\nshows the convergence of the principal generalized eigenvector and eigenvalue. The\\nclosed form solution is obtained after collecting all of the signal and interference\\nsamples. In order to measure the accuracy of the algorithms, we compute the direction\\ncosine of the estimated principal generalized eigenvector and the generalized eigenvector\\ncomputed by the conventional method. The optimum value is one. We also show the\\nestimated principal generalized eigenvalue in Figure 1b. The results show that both\\nalgorithms converge after the 4th bit of signal.\\n-\\n\\nAlgonthm (1 0)\\n\\n-\\n\\n-\\n\\nAlgonlhm (8)\\n\\nAlgonthm (10)\\n- Algonlhm (8)\\n35 ...----.---r--r----r-....-,-..,--.......,--...----.---,\\n\\n1.1r--.----T---~--__r~r__-,--.......,\\n\\n. ._09.rf\\n\\nCLOSl!D FORM SOUlTlON\\n1.0 ?? ? ? ???.... .? ???.........????.?..??.?..\\n? ?......\\n\\n~\\n....\\n\\nlll\\n\\n08\\n\\n~\\n\\n:; 07\\n\\n/--\\n\\nI\\n\\n.-- - - - -\\n\\n25\\n\\nI\\n\\nI\\n\\nIii\\n\\n~20\\n\\n~~: /'\\n\\n~\\n\\n....\\n\\n;::: 04\\n\\n~\\n\\n03\\n\\nIii\\n\\nQ\\n\\nOJ\\n\\n~\\n\\n13\\n\\n~\\n\\nI\\n\\n15\\n\\nI\\n\\nI::\\n\\n10 III\\n\\nIii\\n\\n!ii ~\\n\\n0.1\\nO.OD?'------=5DD:-----lI~m----:-:I5DD'::-'\\n\\nNUMBER OF SAMPLES\\n\\n(a)\\n\\n?D?'------5DD~---~I~----IJ5DD---~DOO\\n\\nNUMBER OF SAMPLES\\n\\n(b)\\n\\nFigure 1. (a) Direction Cosine of Estimated First Principal Generalized Eigenvector, and\\n(b) Estimated First Principal Generalized Eigenvalue.\\nReferences\\nC.Chatterjee and V.Roychowdhury (1996), \\\"Statistical Risk Analysis for Classification and\\nFeature Extraction by Multilayer Perceptrons\\\", Proceedings IEEE Int 'l Conference on Neural\\nNetworks, Washington D.C.\\nK.Fukunaga (1990), Introduction to Statistical Pattern Recognition, 2nd Edition, New York:\\nAcademic Press.\\nP.Gallinari, S.Thiria, F.Badran, F.Fogelman-Soulie (1991), \\\"On the Relations Between\\nDiscriminant Analysis and Multilayer Perceptrons\\\", Neural Networks, Vol. 4, pp. 349-360.\\nL.Ljung (1977), \\\"Analysis of Recursive Stochastic Algorithms\\\", IEEE Transactions on Automatic\\nControl, Vol. AC-22, No. 4, pp. 551-575.\\nA.R.Webb and D.Lowe (1990), \\\"The Optimised Internal Representation of Multilayer Classifier\\nNetworks Perfonns Nonlinear Discriminant Analysis\\\", Neural Networks, Vol. 3, pp. 367-375.\\nM.D.Zoltowski, C.Chatterjee, V.Roychowdhury and J.Ramos (1996), \\\"Blind Adaptive 2D RAKE\\nReceiver for CDMA Based on Space-Time MVDR Processing\\\", submitted to IEEE Transactions\\non Signal Processing.\\n\\n\\f\",\n          \"Directed Regression\\n\\nYi-hao Kao\\nStanford University\\nStanford, CA 94305\\nyihaokao@stanford.edu\\n\\nBenjamin Van Roy\\nStanford University\\nStanford, CA 94305\\nbvr@stanford.edu\\n\\nXiang Yan\\nStanford University\\nStanford, CA 94305\\nxyan@stanford.edu\\n\\nAbstract\\nWhen used to guide decisions, linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent\\nuse to make decisions. When there are multiple response variables and features\\ndo not perfectly capture their relationships, it is beneficial to account for the decision objective when computing regression coefficients. Empirical optimization\\ndoes so but sacrifices performance when features are well-chosen or training data\\nare insufficient. We propose directed regression, an efficient algorithm that combines merits of ordinary least squares and empirical optimization. We demonstrate\\nthrough a computational study that directed regression can generate significant\\nperformance gains over either alternative. We also develop a theory that motivates\\nthe algorithm.\\n\\n1\\n\\nIntroduction\\n\\nWhen used to guide decision-making, linear regression analysis typically treats estimation of regression coefficients separately from their use to make decisions. In particular, estimation is carried\\nout via ordinary least squares (OLS) without consideration of the decision objective. The regression\\ncoefficients are then used to optimize decisions.\\nWhen there are multiple response variables and features do not perfectly capture their relationships,\\nit is beneficial to account for the decision objective when computing regression coefficients. Imperfections in feature selection are common since it is difficult to identify the right features and the\\nnumber of features is typically restricted in order to avoid over-fitting.\\nEmpirical optimization (EO) is an alternative to OLS which selects coefficients that minimize empirical loss in the training data. Though it accounts for the decision objective when computing\\nregression coefficients, EO sacrifices performance when features are well-chosen or training data is\\ninsufficient.\\nIn this paper, we propose a new algorithm ? directed regression (DR) ? which is a hybrid between\\nOLS and EO. DR selects coefficients that are a convex combination of those that would be selected by OLS and those by EO. The weights of OLS and EO coefficients are optimized via crossvalidation.\\nWe study DR for the case of decision problems with quadratic objective functions. The algorithm\\ntakes as input a training set of data pairs, each consisting of feature vectors and response variables,\\ntogether with a quadratic loss function that depends on decision variables and response variables.\\nRegression coefficients are computed for subsequent use in decision-making. Each future decision\\ndepends on newly sampled feature vectors and is made prior to observing response variables with\\nthe goal of minimizing expected loss.\\nWe present computational results demonstrating that DR can substantially outperform both OLS and\\nEO. These results are for synthetic problems with regression models that include subsets of relevant\\n1\\n\\n\\ffeatures. In some cases, OLS and EO deliver comparable performance while DR reduces expected\\nloss by about 20%. In none of the cases considered does either OLS or EO outperform DR.\\nWe also develop a theory that motivates DR. This theory is based on a model in which selected\\nfeatures do not perfectly capture relationships among response variables. We prove that, for this\\nmodel, the optimal vector of coefficients is a convex combination of those that would be generated\\nby OLS and EO.\\n\\n2\\n\\nLinear Regression for Decision-Making\\n\\nSuppose we are given a set of training data pairs O = {(x(1) , y (1) ), ? ? ? , (x(N ) , y (N ) )}. Each nth\\n(n)\\n(n)\\ndata pair is comprised of feature vectors x1 , . . . , xK ? <M and a vector y (n) ? <M of response\\nK\\nvariables. We would like\\nPto compute regression coefficients r ? < so that given a data pair (x, y),\\nthe linear combination k rk xk of feature vectors estimates the expectation of y conditioned on x.\\nWe restrict attention to cases where M > 1, with special interest in problems where M is large,\\nbecause it is in such situations that DR offers the largest performance gains.\\nWe consider a setting where the regression model is used to guide future decisions. In particular,\\nafter computing regression coefficients, each time we observe feature vectors x1 , . . . , xK we will\\nhave to select a decision u ? <L before observing the response vector y. The choice incurs a loss\\n`(u, y) = u> G1 u + u> G2 y,\\nwhere the matrices G1 ? <L?L and G2 ? <L?M are known, and the former is positive definite and\\nsymmetric. We aim to minimize expected loss, assuming that the conditional expectation of y given\\nPK\\nx is k=1 rk xk . As such, given x and r, we select a decision\\n? K\\n!\\nK\\nX\\n1 ?1 X\\nrk xk .\\nur (x) = argmin ` u,\\nrk xk = ? G1 G2\\n2\\nu\\nk=1\\n\\nk=1\\n\\nThe question is how best to compute the regression coefficients r for this purpose.\\nTo motivate the setting we have described, we offer a hypothetical application.\\nExample 1. Consider an Internet banner ad campaign that targets M classes of customers. An\\naverage revenue of ym is received per customer of class m that the campaign reaches. This quantity\\nis random and influenced by K observable factors x1m , . . . , xKm . These factors may be correlated\\nacross customers classes; for example, they could capture customer preferences as they relate to\\nad content or how current economic conditions affect customers. For each mth class, the cost of\\nreaching the um th customer increases with um because ads are first targeted at customers that can\\nbe reached at lower cost. This cost is quadratic, so that we pay ?m u2m to reach um customers, where\\n?m is a known constant.\\nThe application we have described fits our general\\nP problem context. It is natural to predict the\\nresponse vector y using a linear combination k rk xk of factors with the regression coefficients\\nrk computed based on past observations O = {(x(1) , y (1) ), ? ? ? , (x(N ) , y (N ) )}. The goal is to\\nmaximize expected revenue less advertising costs. This gives rise to a loss function that is quadratic\\nin u and y:\\nM\\nX\\n`(u, y) =\\n(?m u2m ? um ym ).\\nm=1\\n\\nOne might ask why not construct M separate linear regression models, one for each response variable, each with a separate set of K coefficients. The reason is that this gives rise to M K coefficients;\\nwhen M is large and data is limited, this could lead to over-fitting. Models of the sort we consider,\\nwhere regression coefficients are shared across multiple response variables, are sometimes referred\\nto as general linear models and have seen a wide range of applications [7, 8]. It is well-known\\nthat the quality of results is highly sensitive to the choice of features, even more so than for models\\ninvolving a single response variable [7].\\n2\\n\\n\\f3\\n\\nAlgorithms\\n\\nOrdinary least squares (OLS) is a conventional approach to computing regression coefficients. This\\nwould produce a coefficient vector\\n?\\n?2\\nN ?\\nK\\n?\\nX\\n? (n) X\\n(n) ?\\nOLS\\nr\\n= argmin\\nrk xk ? .\\n(1)\\n?y ?\\n?\\n?\\nr?<K\\nn=1\\n\\nk=1\\n\\nNote that OLS does not take the decision objective into account when computing regression coefficients. Empirical optimization (EO), as studied for example in [2, 6], offers an alternative that does\\nso. This approach minimizes empirical loss on the training data:\\nrEO = argmin\\n\\nN\\nX\\n\\n`(ur (x(n) ), y (n) ).\\n\\n(2)\\n\\nr?<K n=1\\n\\nNote that EO does not explicitly aim to estimate the conditional expectation of the response vector.\\nInstead it focusses on decision loss that would be incurred with the training data. Both rOLS and\\nrEO can be computed efficiently by minimizing convex quadratic functions.\\nAs we will see in our computational and theoretical analyses, OLS and EO can be viewed as two\\nextremes, each offering room for improvement. In this paper, we propose an alternative algorithm\\n? directed regression (DR) ? which produces a convex combination rDR = (1 ? ?)rOLS + ?rEO\\nof coefficients computed by OLS and EO. The term directed is chosen to indicate that DR is influenced by the decision objective though, unlike EO, it does not simply minimize empirical loss. The\\nparameter ? ? [0, 1] is computed via cross-validation, with an objective of minimizing average loss\\non validation data. Average loss is a convex quadratic function of ?, and therefore can be easily\\nminimized over ? ? [0, 1].\\nDR is designed to generate decisions that are more robust to imperfections in feature selection than\\nOLS. As such, DR addresses issues similar to those that have motivated work in data-driven robust\\noptimization, as surveyed in [3]. Our focus on making good decisions despite modeling inaccuracies\\nalso complements recent work that studies how models deployed in practice can generate effective\\ndecisions despite their failure to pass basic statistical tests [4].\\n\\n4\\n\\nComputational Results\\n\\nIn this section, we present results from applying OLS, EO, and DR to synthetic data. To generate a\\ndata set, we first sample parameters of a generative model as follows:\\n1. Sample P matrices C1 , . . . , CP ? <M ?Q , with each entry from each matrix drawn independently from N (0, 1).\\n2. Sample a vector r? ? <P from N (0, I).\\n3. Sample Ga ? <L?L and Gb ? <L?M , with each entry of each matrix drawn from N (0, 1).\\n>\\nLet G1 = G>\\na Ga and G2 = Ga Gb .\\nGiven generative model parameters C1 , . . . , CP and r?, we sample each training data pair (x(n) , y (n) )\\nas follows:\\n2\\n1. Sample a vector ?(n) ? <Q from N (0, I) and a vector w(n) ? <M from N (0, ?w\\nI).\\nP\\nP\\n(n)\\n(n)\\n(n)\\n2. Let y = i=1 r?i Ci ? + w .\\n(n)\\n\\n3. For each k = 1, 2, ? ? ? , K, let xk\\n\\n= Ck ?(n) .\\n\\nThe vector ?(n) can be viewed as a sample from an underlying information space. The matrices\\nC1 , . . . , CP extract feature vectors from ?(n) . Note that, though response variables depend on P\\nfeature vectors, only K ? P are used in the regression model.\\nGiven generative model parameters and a coefficient vector r ? <K , it is easy to evaluate the\\nexpected loss `(r) = Ex,y [`(ur (x), y)]. It is also easy to evaluate the minimal expected loss `? =\\n3\\n\\n\\f10000\\n\\n6000\\nOLS\\nEO\\nDR\\n\\n6000\\n4000\\n2000\\n0\\n10\\n\\nOLS\\nEO\\nDR\\n\\n5000\\nExcess Loss\\n\\nExcess Loss\\n\\n8000\\n\\n4000\\n3000\\n2000\\n1000\\n\\n20\\n\\n30\\nN\\n\\n40\\n\\n0\\n45\\n\\n50\\n\\n50\\n\\n55\\n\\n60\\n\\nK\\n\\n(a)\\n\\n(b)\\n\\nFigure 1: (a) Excess losses delivered by OLS, EO, and DR, for different numbers N of training\\nsamples. (b) Excess losses delivered by OLS, EO, and DR, using different numbers K of the 60\\nfeatures.\\nminr Ex,y [`(ur (x), y)]. We will assess each algorithm in terms of the excess loss `(r) ? `? delivered\\nby the coefficient vector r that the algorithm computes. Excess loss is nonnegative, and this allows\\nus to make comparisons in percentage terms.\\nWe carried out two sets of experiments to compare the performance of OLS, EO, and DR. In the\\nfirst set, we let M = 15, L = 15, P = 60, Q = 20, ?w = 5, and K = 50. For each N ?\\n{10, 15, 20, 30, 50}, we ran 100 trials, each with an independently sampled generative model and\\ntraining data set. In each trial, each algorithm computes a coefficient vector given the training data\\nand loss function. With DR, ? is selected via leave-one-out cross-validation when N ? 20, and via\\n5-fold cross-validation when N > 20. Figure 1(a) plots excess losses averaged over trials. Note that\\nthe excess loss incurred by DR is never larger than that of OLS or EO. Further, when N = 20, the\\nexcess loss of OLS and EO are both around 20% larger than that of DR. For small N , OLS is as\\neffective as DR, while, EO becomes as effective as DR as N grows large.\\nIn the second set of experiments, we use the same parameter values as in the first set, except we fix\\nN = 20 and consider use of K ? {45, 50, 55, 58, 60} feature vectors. Again, we ran 100 trials for\\neach K, applying the three algorithms as in the first set of experiments. Figure 1(b) plots excess\\nlosses averaged over trials. Note that when K = 55, DR delivers excess loss around 20% less than\\nEO and OLS. When K = P = 60, there are no missing features and OLS matches the performance\\nof DR.\\nFigure 2 plots the values of ? selected by cross-validation, each averaged over the 100 trials, as\\na function of N and K. As the number of training samples N grows, so does ?, indicating that\\nDR is weighted more heavily toward EO. As the number of feature vectors K grows, ? diminishes,\\nindicating that DR is weighted more heavily toward OLS.\\n\\n5\\n\\nTheoretical Analysis\\n\\nIn this section, we formulate a generative model for the training data and future observations. For\\nthis model, optimal coefficients are convex combinations of rOLS and rEO . As such, our model and\\nanalysis motivate the use of DR.\\n5.1\\n\\nModel\\n\\nIn this section, we describe a generative model that samples the training data set, as well as ?missing\\nfeatures,? and a representative future observation. We then formulate an optimization problem where\\nthe objective is to minimize expected loss on the future observation conditioned on the training data\\nand missing features. It may seem strange to condition on missing features since in practice they are\\nunavailable when computing regression coefficients. However, we will later establish that optimal\\n4\\n\\n\\f0.8\\n\\n0.6\\n\\n0.6\\n\\n0.4\\n\\n0.4\\n\\n?\\n\\n?\\n\\n0.8\\n\\n0.2\\n\\n0\\n10\\n\\n0.2\\n\\n20\\n\\n30\\nN\\n\\n40\\n\\n0\\n45\\n\\n50\\n\\n50\\n\\n55\\n\\n60\\n\\nK\\n\\n(a)\\n\\n(b)\\n\\nFigure 2: (a) The average values of selected ?, for different numbers N of training samples. (b) The\\naverage values of selected ?, using different numbers K of the 60 features.\\ncoefficients are convex combinations of rOLS and rEO , each of which can be computed without\\nobserving missing features. Since directed regression searches over these convex combinations, it\\nshould approximate what would be generated by a hypothetical algorithm that observes missing\\nfeatures.\\nWe will assume that each feature, whether observed or missing, is a linear function of an ?information vector? drawn from <Q . Specifically, the N training data samples depend on information\\nvectors ?(1) , . . . , ?(N ) ? <Q . A linear function mapping an information vector to a feature vector\\ncan be represented by a matrix in <M ?Q , and to describe our generative model, it is useful to define\\nan inner product for such matrices. In particular, we define the inner product between matrices A\\nand B by\\nN\\n1 X\\n(A?(n) )> (B?(n) ).\\nhA, Bi =\\nN n=1\\nOur generative model takes several parameters as input. First, there are the number of samples\\nN , the number of response variables M , and the number of feature vectors K. Second, a parameter\\n?Q specifies the expected dimension of the information vector. Finally, there are standard deviations\\n?r , ?? , and ?w , of observed feature coefficients, missing feature coefficients, and noise, respectively.\\nGiven parameters N , M , K, ?Q , ?r , ?? , and ?w , the generative model produces data as follows:\\n1. Sample Q from the geometric distribution with mean ?Q .\\n2. Sample ?(1) , . . . , ?(N ) ? <Q from N (0, IQ ).\\n3. Sample C1 , . . . , CK and D1 , ? ? ? , DJ ? <M ?Q with each entry i.i.d. from N (0, 1), where\\nK + J = M Q.\\n4. Apply the Gram-Schmidt algorithm with respect to the inner product defined\\n? 1, . . . , D\\n? J from the sequence\\nabove to generate an orthonormal basis C?1 , . . . , C?K , D\\nC1 , . . . , CK , D1 , . . . , DJ .\\n5. Sample r? ? <K from N (0, ?r2 IK ) and r?? ? <J from N (0, ??2 IJ ).\\n2\\n6. For n = 1, ? ? ? , N , sample w(n) ? <M from N (0, ?w\\nIM ), and let\\ni\\nh\\nx(n) = C1 ?(n) ? ? ? CK ?(n) ,\\ni\\nh\\n? 1 ?(n) ? ? ? D\\n? J ?(n) ,\\nz (n) = D\\n\\ny (n) =\\n\\nK\\nX\\n\\n(n)\\n\\nrk? xk +\\n\\nJ\\nX\\nj=1\\n\\nk=1\\n\\n5\\n\\n(n)\\n\\nrj?? zj\\n\\n+ w(n) .\\n\\n(3)\\n(4)\\n(5)\\n\\n\\f2\\n7. Sample ?? uniformly from {?(1) , ? ? ? , ?(N ) } and w\\n? ? <M from N (0, ?w\\nIM ). Generate x\\n?,\\nz?, and y? by the same functions in (3), (4), and (5).\\n\\nThe samples z (1) , . . . , z (N ) , z? represent missing features. The Gram-Schmidt procedure ensures two\\n? j i = 0, missing features are uncorrelated with observed features. If\\nproperties. First, since hCk , D\\nthis were not the case, observed features would provide information about missing features. Second,\\n? 1, . . . , D\\n? J are orthonormal, the distribution of missing features is invariant to rotations in the\\nsince D\\nJ-dimensional subspace from which they are drawn. In other words, all directions in that space are\\nequally likely.\\nWe define an augmented training set O = {(x(1) , z (1) , y (1) ), ? ? ? , (x(N ) , z (N ) , y (N ) )} and consider\\nselecting regression coefficients r? ? <K that solve\\nmin E[`(ur (?\\nx), y?)|O].\\n\\nr?<K\\n\\nNote that the probability distribution here is implicitly defined by our generative model, and as such,\\nr? may depend on N , M , K , ?Q , ?r , ?? , ?w , and O.\\n5.2\\n\\nOptimal Solutions\\n\\nOur primary interest is in cases where prior knowledge about the coefficients r? is weak and does\\nnot significantly influence r?. As such, we will from here on restrict attention to the case where ?r is\\nasymptotically large. Hence, r? will no longer depend on ?r .\\nIt is helpful to consider two special cases. One is where ?? = 0 and the other is where ?? is\\nasymptotically large. We will refer to r? in these extreme cases as r?0 and r?? . The following theorem\\nestablishes that these extremes are delivered by OLS and EO.\\nTheorem 1. For all N , M , K, ?Q , ?w , and O,\\n?\\n?2\\nN ?\\nK\\n?\\nX\\n? (n) X\\n(n) ?\\nr?0 = argmin\\nrk xk ?\\n?y ?\\n?\\n?\\nr?<K\\nn=1\\n\\nk=1\\n\\nand\\nr?? = argmin\\nr?<K\\n\\nN\\nX\\n\\n`(ur (x(n) ), y (n) ).\\n\\nn=1\\n\\nNote that ?? represents the degree of bias in a regression model that assumes there are no missing\\nfeatures. Hence, the above theorem indicates that OLS is optimal when there is no bias while EO\\nis optimal as the bias becomes asymptotically large. It is also worth noting that the coefficient\\nvectors r?0 and r?? can be computed without observing the missing features, though r? is defined by\\nan expectation that is conditioned on their realizations. Further, computation of r?0 and r?? does not\\nrequire knowledge of Q or ?w .\\nOur next theorem establishes that the coefficient vector r? is always a convex combination of r?0 and\\nr?? .\\nTheorem 2. For all N , M , K, ?Q , ?w , ?? , and O,\\nr? = (1 ? ?)?\\nr0 + ??\\nr? ,\\nwhere ? =\\n\\n1\\n\\n?2\\n\\nw\\n1+ N ?\\n2\\n\\n.\\n\\n?\\n\\nOur two theorems together imply that, with an appropriately selected ? ? [0, 1], (1 ? ?)rOLS +\\n?rEO = r?. This suggests that directed regression, which optimizes ? via cross-validation to generate\\na coefficient vector rDR = (1 ? ?)rOLS + ?rEO , should approximate r? well without observing the\\nmissing features or requiring knowledge of Q, ?? , or ?w .\\n6\\n\\n\\f5.3\\n\\nInterpretation\\n\\nTo develop intuition for our results, we consider an idealized situation where the coefficients r? and\\nr?? are provided to us by an oracle. Then the optimal coefficient vector would be\\nrO = argmin E[`(ur (?\\nx), y?)|O, r? , r?? ].\\nr?<K\\n\\nIt can be shown that rOLS is a biased estimator of rO , while rEO is an unbiased one. However,\\nthe variance of rOLS is smaller than that of rEO . The optimal tradeoff is indeed captured by the\\nvalue of ? provided in Theorem 2. In particular, as the number of training samples N increases,\\nvariance diminishes and ? approaches 1, placing increasing weight on EO. On the other hand, as\\nthe number of observed features K increases, model bias decreases and ? approaches 0, placing\\nincreasing weight on OLS. Our experimental results demonstrate that the value of ? selected by\\ncross-validation exhibits the same behavior.\\n\\n6\\n\\nExtensions\\n\\nThough we only treated linear models and quadratic objective functions, our work suggests that\\nthere can be significant gains in broader problem settings from a tighter coupling between machine\\nlearning and decision-making. In particular, machine learning algorithms should factor decision\\nobjectives into the learning process. It will be interesting to explore how to do this with other\\nclasses of models and objectives.\\nOne might argue that feature mis-specification is not a critical issue in light of effective methods\\nfor subset selection. In particular, rather than selecting a few features and facing the consequences\\nof model bias, one might select an enormous set of features and apply a method like the lasso [10]\\nto identify a small subset. Our view is that even this enormous set will result in model biases that\\nmight be ameliorated by generalizations of DR. There is also the concern that data requirements\\ngrow with the size of the large feature set, albeit slowly. Understanding how to synthesize DR with\\nsubset selection methods is an interesting direction for future research.\\nAnother issue that should be explored is the effectiveness of cross-validation in optimizing ?. In\\nparticular, it would be helpful to understand how the estimate relates to the ideal value of ? identified\\nby Theorem 2. More general work on the selection of convex combinations of models (e.g., [1, 5])\\nmay lend insights to our setting.\\nLet us close by mentioning that the ideas behind DR ought to play a role in reinforcement learning\\n(RL) as presented in [9]. RL algorithms learn from experience to predict a sum of future rewards\\nas a function of a state, typically by fitting a linear combination of features of the state. This socalled approximate value function is then used to guide sequential decision-making. The problem\\nwe addressed in this paper can be viewed as a single-period version of RL, in the sense that each\\ndecision incurs an immediate cost but bears no further consequences. It would be interesting to\\nextend our idea to the multi-period case.\\n\\nAcknowledgments\\nWe thank James Robins for helpful comments and suggestions. The first author is supported by a\\nStanford Graduate Fellowship. This research was supported in part by the National Science Foundation through grant CMMI-0653876.\\n\\nAppendix\\nh\\ni\\nh\\ni\\n(n)\\n(n)\\n(n)\\n(n)\\nProof of Theorem 1. For each n, let x(n) = x(n)\\n,\\nz\\n=\\n.\\n?\\n?\\n?\\nx\\nz\\n?\\n?\\n?\\nz\\n1\\n1\\nK\\nJ\\n? (1)>\\n?\\n?\\n?\\n>\\n>\\nLet X\\n=\\n, Z\\n=\\n, Y\\n=\\nx\\n? ? ? x(N )>\\nz (1)> ? ? ? z (N )>\\n? (1)>\\n?\\n>\\n?\\n??\\n?\\n?\\n(N )>\\n, r? = E[r |O], r? = E[r |O]. For any matrix V , let V denote\\ny\\n??? y\\n? j i = 0, ? k, j implies that each column of X is orthogonal to\\n(V > V )?1 V > . Recall that hCk , D\\n7\\n\\n\\feach column of Z. Because r? , r?? , O are jointly Gaussian, as ?r ? ?, we have\\n?2\\n?\\n?\\n?\\n?\\nN ?\\nK\\nJ\\nJ\\nX\\nX\\nX\\n?\\n1 X?\\nr?\\n(n)\\n(n)\\n(n)\\n?\\n?\\n? + 1\\ny\\n?\\nr\\nx\\n?\\nr\\nz\\nrj?2\\n= argmin 2\\nk\\n?\\nj\\nj\\nk\\n?\\n?\\n2\\nr?\\n2?\\n(r,r? ) 2?w n=1 ?\\n?\\n?\\nj=1\\nj=1\\nk=1\\n#\\n?? 1\\n??\\n? ? 1\\n??2 \\\"\\n>\\n?1\\n1\\n?\\n?\\n(X X) X > Y\\nX ?w Z\\nr\\nY\\n?\\n?\\nw\\n?\\n?\\n2\\nw\\n.\\n?\\n= argmin ?\\n=\\n?\\n1\\nr? ?\\n0\\n0\\n(Z > Z + ?w2 I)?1 Z > Y\\n(r,r ? )\\n?? IJ\\n?\\n? (1)>\\n?>\\n?1\\n?1\\nLet a(n) = G1 2 G2 x(n) , b(n) = G1 2 G2 z (n) , A =\\n, B =\\na\\n? ? ? a(N )>\\n? (1)>\\n?\\n(N )> > . We have\\nb\\n??? b\\nr? =\\n\\nargmin E[`(ur (?\\nx), y?)|O] = argmin\\nr\\n\\nr\\n\\n=\\n\\nargmin\\nr\\n\\n=\\n\\nargmin\\nr\\n\\n=\\n\\nN\\nX\\n\\nN\\n1 X\\nEy?[`(ur (?\\nx), y?)|?\\nx = x(n) , O]\\nN n=1\\n\\nur (x(n) )> G1 ur (x(n) ) + ur (x(n) )> G2 E[?\\ny |?\\nx = x(n) , O]\\n\\nn=1\\nN\\nX\\n1\\n1 > (n)> (n)\\nr a\\na r ? r> a(n)> (a(n) r? + b(n) r?? )\\n4\\n2\\nn=1\\n\\nr? + A? B?\\nr? = X ? Y + A? B(Z > Z +\\n\\n2\\n?w\\nI)?1 Z > Y.\\n??2\\n\\n(6)\\n\\nTaking ?? ? 0 and ?? ? ? yields\\nr?0 = X ? Y ,\\nr?? = X ? Y + A? BZ ? Y .\\nThe first part of the theorem then follows because\\n?\\n?2\\nN ?\\nK\\n?\\nX\\n? (n) X\\n(n) ?\\n2\\n?\\nr?0 = X Y = argmin kY ? Xrk = argmin\\nrk xk ? .\\n?y ?\\n?\\n?\\nr\\nr\\nn=1\\n\\n(7)\\n(8)\\n\\nk=1\\n\\nWe now prove the second part. Note that\\nargmin\\nr\\n\\nN\\nX\\n\\n`(ur (x(n) ), y (n) ) = argmin\\nr\\n\\nn=1\\n\\n= argmin r> A> Ar ? 2r>\\nr\\n\\nwhere h\\n\\n(n)\\n\\n=\\n\\nN\\nX\\n\\nur (x(n) )> G1 ur (x(n) ) + ur (x(n) )> G2 y (n)\\n\\nn=1\\n\\nh(n)> y (n) = (A> A)?1 H > Y,\\n\\nn=1\\n?1\\n(n)\\nG>\\n2 G1 G2 x\\n\\nN\\nX\\n\\nand H =\\n\\n?\\n?\\n\\n?\\nhk = ?\\n\\nh(1)>\\n\\n???\\n\\nh(N )>\\n\\n?1\\n(1)\\nG>\\n2 G1 G2 Ck ?\\n\\n?>\\n?\\n\\n. Each kth column of H\\n\\n?\\n..\\n?\\n.\\n> ?1\\n(N )\\nG2 G1 G2 Ck ?\\n\\n?1\\nM ?Q\\n? 1, ? ? ? , D\\n? J }.\\nis in span{col X, col Z} because G>\\n= span{C1 , ? ? ? , CK , D\\n2 G1 G2 Ck ? <\\n0\\n?\\n?\\nSince the residual Y = Y ? XX Y ? ZZ Y upon projecting Y onto span {col X, col Z} is\\n0\\n> 0\\n>\\northogonal to the subspace, we have h>\\nk Y = 0, ? k and hence H Y = 0. This implies H Y =\\n>\\n?\\n>\\n?\\n(n)> (n)\\n(n)> (n)\\n(n)> (n)\\n(n)> (n)\\nH XX Y + H ZZ Y . Further, since a\\na\\n=h\\nx ,a\\nb\\n=h\\nz , ? n, we\\nhave\\n?\\n?\\nr?? = X ? Y + A? BZ ? Y = (A> A)?1 A> AX ? Y + A> BZ ? Y\\n?\\n?\\n= (A> A)?1 H > XX ? Y + H > ZZ ? Y = (A> A)?1 H > Y.\\n\\n? i, D\\n? j i = 1{i = j}, we have Z > Z = N I. Plugging this into (6)\\nProof of Theorem 2. Because hD\\nand comparing the resultant expression with (7) and (8) yield the desired result.\\n8\\n\\n\\fReferences\\n[1] J.-Y. Audibert. Aggregated estimators and empirical complexity for least square regression.\\nAnnales de l?Institut Henri Poincare Probability and Statistics, 40(6):685?736, 2004.\\n[2] P. L. Bartlett and S. Mendelson. Empirical minimization. Probability Theory and Related\\nFields, 135(3):311?334, 2006.\\n[3] D. Bertsimas and A. Thiele. Robust and data-driven optimization: Modern decision-making\\nunder uncertainty. In Tutorials on Operations Research. INFORMS, 2006.\\n[4] O. Besbes, R. Philips, and A. Zeevi. Testing the validity of a demand model: An operations\\nperspective. 2007.\\n[5] F. Bunea, A. B. Tsybakov, and M. H. Wegkamp. Aggregation for Gaussian regression. The\\nAnnals of Statistics, 35(4):1674?1697, 2007.\\n[6] D. Haussler. Decision theoretic generalizations of the PAC model for neural net and other\\nlearning applications. Information and Computation, 100:78?150, 1992.\\n[7] K. Kim and N. Timm. Univariate and Multivariate General Linear Models: Theory and\\nApplications with SAS. Chapman & Hall/CRC, 2006.\\n[8] K. E. Muller and P. W. Stewart. Linear Model Theory: Univariate, Multivariate, and Mixed\\nModels. Wiley, 2006.\\n[9] R. S. Sutton and A. G. Barto. Reinforcement Learning: An Introduction. MIT Press, Cambridge, MA, 1998.\\n[10] R. Tibshirani. Regression shrinkage and selection via the lasso. Journal of Royal Statistical\\nSociety, 1996.\\n\\n9\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "papers"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-631b99dc-2a48-42e3-917a-144103c52ce9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5387</th>\n",
              "      <td>Fixed-Length Poisson MRF:\\nAdding Dependencies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>Adaptive Caching by Refetching\\n\u0001\\n\\nRobert B....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4106</th>\n",
              "      <td>Topology Constraints in Graphical Models\\n\\nMa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5331</th>\n",
              "      <td>A Universal Primal-Dual Convex Optimization Fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5153</th>\n",
              "      <td>Scalable Inference for Gaussian Process Models...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-631b99dc-2a48-42e3-917a-144103c52ce9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-631b99dc-2a48-42e3-917a-144103c52ce9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-631b99dc-2a48-42e3-917a-144103c52ce9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93f676d6-339c-45c6-9f0f-020dd785ba46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93f676d6-339c-45c6-9f0f-020dd785ba46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93f676d6-339c-45c6-9f0f-020dd785ba46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             paper_text\n",
              "5387  Fixed-Length Poisson MRF:\\nAdding Dependencies...\n",
              "1424  Adaptive Caching by Refetching\\n\u0001\\n\\nRobert B....\n",
              "4106  Topology Constraints in Graphical Models\\n\\nMa...\n",
              "5331  A Universal Primal-Dual Convex Optimization Fr...\n",
              "5153  Scalable Inference for Gaussian Process Models..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove the columns\n",
        "papers = papers.drop(columns=['id', 'title', 'abstract',\n",
        "                              'event_type', 'pdf_name', 'year'], axis=1)\n",
        "\n",
        "# sample only 100 papers\n",
        "papers = papers.sample(100)\n",
        "\n",
        "# Print out the first rows of papers\n",
        "papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ5YoUgm2SDX"
      },
      "source": [
        "##### Remove punctuation/lower casing\n",
        "\n",
        "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "onCQoKvw2SDX",
        "outputId": "eab886e8-a37f-4fcf-efa2-511ac7f17594"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5387</th>\n",
              "      <td>fixed-length poisson mrf:\\nadding dependencies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>adaptive caching by refetching\\n\u0001\\n\\nrobert b ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4106</th>\n",
              "      <td>topology constraints in graphical models\\n\\nma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5331</th>\n",
              "      <td>a universal primal-dual convex optimization fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5153</th>\n",
              "      <td>scalable inference for gaussian process models...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "5387    fixed-length poisson mrf:\\nadding dependencies...\n",
              "1424    adaptive caching by refetching\\n\u0001\\n\\nrobert b ...\n",
              "4106    topology constraints in graphical models\\n\\nma...\n",
              "5331    a universal primal-dual convex optimization fr...\n",
              "5153    scalable inference for gaussian process models...\n",
              "Name: paper_text_processed, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the regular expression library\n",
        "import re\n",
        "\n",
        "# Remove punctuation\n",
        "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "\n",
        "# Convert the titles to lowercase\n",
        "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "# Print out the first rows of papers\n",
        "papers['paper_text_processed'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B9NdWJJ2SDX"
      },
      "source": [
        "##### Tokenize words and further clean-up text\n",
        "\n",
        "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtcCNWJ-2SDX",
        "outputId": "c437ae7c-3ef1-4f09-988c-755e35c46353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fixed', 'length', 'poisson', 'mrf', 'adding', 'dependencies', 'to', 'the', 'multinomial', 'david', 'inouye', 'pradeep', 'ravikumar', 'inderjit', 'dhillon', 'department', 'of', 'computer', 'science', 'university', 'of', 'texas', 'at', 'austin', 'csutexasedu', 'abstract', 'we', 'propose', 'novel', 'distribution']\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data = papers.paper_text_processed.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXcbYJiX2SDX"
      },
      "source": [
        "** **\n",
        "#### Step 3: Phrase Modeling: Bigram and Trigram Models\n",
        "** **\n",
        "\n",
        "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring. Some examples in our example are: 'back_bumper', 'oil_leakage', 'maryland_college_park' etc.\n",
        "\n",
        "Gensim's Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold.\n",
        "\n",
        "*The higher the values of these param, the harder it is for words to be combined.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note\n",
        "\n",
        "create bigram and trigram models from the data.\n",
        "\n",
        "Set a threshold to filter out less significant phrases."
      ],
      "metadata": {
        "id": "FDwcRQOENJ2Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGs1U6Be2SDX"
      },
      "outputs": [],
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed4VZ4V2SDY"
      },
      "source": [
        "#### Remove Stopwords, Make Bigrams and Lemmatize\n",
        "\n",
        "The phrase models are ready. Let’s define the functions to remove the stopwords, make trigrams and lemmatization and call them sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4y0HVRX2SDY",
        "outputId": "8770c8f0-68e8-4ba7-f47f-6352b35de9af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# NLTK Stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpF4RtIl2SDY"
      },
      "outputs": [],
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yChBGWk2SDY"
      },
      "source": [
        "Let's call the functions in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFGXLAwy2SDY",
        "outputId": "6d251527-7173-4f68-db53-d7a505db649d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z1suTX22SDY",
        "outputId": "df915e85-8276-47f5-906f-4c7901fb0818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fix', 'length', 'poisson_mrf', 'add', 'dependency', 'abstract', 'propose', 'novel', 'distribution', 'generalize', 'multinomial', 'distribution', 'enable', 'dependency', 'dimension', 'novel', 'distribution', 'base', 'parametric', 'form', 'poisson_mrf', 'model', 'fundamentally', 'different', 'domain', 'restriction', 'fix', 'length', 'vector', 'multinomial']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ycvibf62SDY"
      },
      "source": [
        "** **\n",
        "#### Step 4: Data transformation: Corpus and Dictionary\n",
        "** **\n",
        "\n",
        "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laJaEEMq2SDY",
        "outputId": "14f81517-afa8-4482-b99f-7550812b6915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 3), (1, 1), (2, 1), (3, 1), (4, 2), (5, 2), (6, 3), (7, 6), (8, 1), (9, 4), (10, 3), (11, 1), (12, 1), (13, 4), (14, 5), (15, 1), (16, 7), (17, 1), (18, 6), (19, 2), (20, 1), (21, 6), (22, 1), (23, 3), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 3)]\n"
          ]
        }
      ],
      "source": [
        "import gensim.corpora as corpora\n",
        "\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RniGjO3V2SDY"
      },
      "source": [
        "** **\n",
        "#### Step 5: Base Model\n",
        "** **\n",
        "\n",
        "We have everything required to train the base LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we'll use default for the base model).\n",
        "\n",
        "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
        "\n",
        "passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcBLMOrF2SDY"
      },
      "outputs": [],
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=10,\n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note\n",
        "\n",
        "the LDA model is created using Gensim's LdaModel, setting parameters like the number of topics and training passes. This model identifies main topics in the dataset, with each topic defined by keywords that indicate its significance. The print_topics() method displays these keywords and their weights, revealing the document's underlying themes."
      ],
      "metadata": {
        "id": "IKVm-gIjNqRr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6T7CAhm2SDZ"
      },
      "source": [
        "** **\n",
        "The above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
        "\n",
        "You can see the keywords for each topic and the weightage(importance) of each keyword using `lda_model.print_topics()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHgUZr8Q2SDZ",
        "outputId": "1e8cc181-749f-4b04-d843-d0eb2fe964b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.016*\"model\" + 0.009*\"cluster\" + 0.009*\"datum\" + 0.009*\"set\" + 0.006*\"use\" '\n",
            "  '+ 0.006*\"number\" + 0.006*\"problem\" + 0.006*\"layer\" + 0.006*\"give\" + '\n",
            "  '0.005*\"train\"'),\n",
            " (1,\n",
            "  '0.011*\"datum\" + 0.010*\"use\" + 0.010*\"set\" + 0.008*\"model\" + 0.007*\"margin\" '\n",
            "  '+ 0.006*\"base\" + 0.006*\"case\" + 0.006*\"parameter\" + 0.005*\"training\" + '\n",
            "  '0.005*\"show\"'),\n",
            " (2,\n",
            "  '0.010*\"function\" + 0.010*\"use\" + 0.007*\"method\" + 0.007*\"model\" + '\n",
            "  '0.007*\"problem\" + 0.006*\"set\" + 0.006*\"result\" + 0.006*\"sense\" + '\n",
            "  '0.006*\"number\" + 0.005*\"objective\"'),\n",
            " (3,\n",
            "  '0.014*\"model\" + 0.009*\"distribution\" + 0.008*\"use\" + 0.007*\"datum\" + '\n",
            "  '0.007*\"function\" + 0.006*\"topic\" + 0.006*\"test\" + 0.006*\"result\" + '\n",
            "  '0.005*\"dataset\" + 0.005*\"process\"'),\n",
            " (4,\n",
            "  '0.019*\"matrix\" + 0.012*\"model\" + 0.011*\"tensor\" + 0.008*\"datum\" + '\n",
            "  '0.008*\"method\" + 0.007*\"use\" + 0.006*\"network\" + 0.006*\"log\" + 0.006*\"time\" '\n",
            "  '+ 0.006*\"show\"'),\n",
            " (5,\n",
            "  '0.019*\"weight\" + 0.012*\"policy\" + 0.011*\"network\" + 0.011*\"function\" + '\n",
            "  '0.008*\"error\" + 0.007*\"use\" + 0.007*\"show\" + 0.007*\"unit\" + 0.006*\"method\" '\n",
            "  '+ 0.006*\"result\"'),\n",
            " (6,\n",
            "  '0.013*\"model\" + 0.011*\"tree\" + 0.009*\"use\" + 0.008*\"image\" + '\n",
            "  '0.007*\"feature\" + 0.007*\"distance\" + 0.007*\"network\" + 0.007*\"set\" + '\n",
            "  '0.006*\"probability\" + 0.006*\"datum\"'),\n",
            " (7,\n",
            "  '0.012*\"set\" + 0.011*\"model\" + 0.010*\"label\" + 0.009*\"network\" + 0.008*\"use\" '\n",
            "  '+ 0.008*\"number\" + 0.008*\"datum\" + 0.007*\"training\" + 0.006*\"method\" + '\n",
            "  '0.006*\"example\"'),\n",
            " (8,\n",
            "  '0.012*\"time\" + 0.012*\"model\" + 0.011*\"state\" + 0.010*\"neuron\" + '\n",
            "  '0.010*\"learn\" + 0.009*\"input\" + 0.008*\"figure\" + 0.008*\"weight\" + '\n",
            "  '0.007*\"use\" + 0.007*\"set\"'),\n",
            " (9,\n",
            "  '0.018*\"model\" + 0.013*\"image\" + 0.011*\"use\" + 0.008*\"set\" + 0.008*\"state\" + '\n",
            "  '0.007*\"learn\" + 0.007*\"sample\" + 0.006*\"figure\" + 0.006*\"program\" + '\n",
            "  '0.005*\"datum\"')]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oyeRaIn2SDZ"
      },
      "source": [
        "#### Compute Model Perplexity and Coherence Score\n",
        "\n",
        "Let's calculate the baseline coherence score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbfsOl1a2SDZ",
        "outputId": "57087de2-adc0-4792-9da6-80c263c09a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.2763171776526517\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPDTOGKM2SDZ"
      },
      "source": [
        "** **\n",
        "#### Step 6: Hyperparameter tuning\n",
        "** **\n",
        "First, let's differentiate between model hyperparameters and model parameters :\n",
        "\n",
        "- `Model hyperparameters` can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
        "\n",
        "- `Model parameters` can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
        "\n",
        "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters:\n",
        "- Number of Topics (K)\n",
        "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
        "- Dirichlet hyperparameter beta: Word-Topic Density\n",
        "\n",
        "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use `C_v` as our choice of metric for performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwMWdlUH2SDZ"
      },
      "outputs": [],
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "\n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k,\n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "\n",
        "    return coherence_model_lda.get_coherence()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di821Mzd2SDZ"
      },
      "source": [
        "Let's call the function, and iterate it over the range of topics, alpha, and beta parameter values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my note\n",
        "\n",
        "This code adjusts LDA model parameters by evaluating combinations of topics, alpha, and beta across two validation sets (75% and 100% of the corpus). It computes coherence scores for each combination, stores the results in a dictionary, and saves them as a CSV file for analysis."
      ],
      "metadata": {
        "id": "s6DD9Rk1OEAV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOqA5e9A2SDZ",
        "outputId": "d2d1d99f-effa-4bd5-890c-0978df2b39d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 540/540 [1:37:05<00:00, 13.00s/it]"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: 'results'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-390bae623936>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./results/lda_tuning_results.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "\n",
        "# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 11\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)),\n",
        "               corpus]\n",
        "\n",
        "corpus_title = ['75% Corpus', '100% Corpus']\n",
        "\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
        "\n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word,\n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "\n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results).to_csv('./results/lda_tuning_results.csv', index=False)\n",
        "    pbar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx7zHoW82SDZ"
      },
      "source": [
        "** **\n",
        "#### Step 7: Final Model\n",
        "** **\n",
        "\n",
        "Based on external evaluation (Code to be added from Excel based analysis), let's train the final model with parameters yielding highest coherence score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l5rNlJdO2SDZ"
      },
      "outputs": [],
      "source": [
        "num_topics = 8\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=num_topics,\n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=0.01,\n",
        "                                           eta=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4psfpx9S2SDa"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKbv9qhu2SDa"
      },
      "source": [
        "** **\n",
        "#### Step 8: Visualize Results\n",
        "** **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Lb9nyffu2SDa"
      },
      "outputs": [],
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pickle\n",
        "import pyLDAvis\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_data_filepath = os.path.join('./results/ldavis_tuned_'+str(num_topics))\n",
        "\n",
        "# # this is a bit time consuming - make the if statement True\n",
        "# # if you want to execute visualization prep yourself\n",
        "if 1 == 1:\n",
        "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "    with open(LDAvis_data_filepath, 'wb') as f:\n",
        "        pickle.dump(LDAvis_prepared, f)\n",
        "\n",
        "# load the pre-prepared pyLDAvis data from disk\n",
        "with open(LDAvis_data_filepath, 'rb') as f:\n",
        "    LDAvis_prepared = pickle.load(f)\n",
        "\n",
        "pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_tuned_'+ str(num_topics) +'.html')\n",
        "\n",
        "LDAvis_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_g-iw1R2SDa"
      },
      "source": [
        "** **\n",
        "#### Closing Notes\n",
        "\n",
        "We started with understanding why evaluating the topic model is essential. Next, we reviewed existing methods and scratched the surface of topic coherence, along with the available coherence measures. Then we built a default LDA model using Gensim implementation to establish the baseline coherence score and reviewed practical ways to optimize the LDA hyperparameters.\n",
        "\n",
        "Hopefully, this article has managed to shed light on the underlying topic evaluation strategies, and intuitions behind it.\n",
        "\n",
        "** **\n",
        "#### References:\n",
        "1. http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
        "2. https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020\n",
        "3. https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
        "4. https://github.com/mattilyra/pydataberlin-2017/blob/master/notebook/EvaluatingUnsupervisedModels.ipynb\n",
        "5. https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
        "6. http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
        "7. http://palmetto.aksw.org/palmetto-webapp/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}